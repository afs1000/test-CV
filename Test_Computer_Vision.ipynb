{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afs1000/test-CV/blob/main/Test_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov5/v70/splash.png\"></a>\n",
        "\n",
        "[‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/models/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "\n",
        "This <a href=\"https://github.com/ultralytics/yolov5\">YOLOv5</a> üöÄ notebook by <a href=\"https://ultralytics.com\">Ultralytics</a> presents simple train, validate and predict examples to help start your AI adventure.<br>We hope that the resources in this notebook will help you get the most out of YOLOv5. Please browse the YOLOv5 <a href=\"https://docs.ultralytics.com/yolov5\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/yolov5\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e69f0a-cbb1-46a0-e007-8c49040534d4"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-381-g15c40626 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 36.6/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "This command uses Git to clone the YOLOv5 repository from GitHub to your local environment, giving you access to YOLOv5 code and files."
      ],
      "metadata": {
        "id": "iGKP3QwBohho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%cd yolov5\n",
        "This command changes the working directory to yolov5, where all the cloned YOLOv5 files are now located"
      ],
      "metadata": {
        "id": "2PjsVcm2o_Gu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "This command installs the required libraries specified in requirements.txt as well as comet_ml (a library for experiment tracking). The -q option suppresses the output to make installation cleaner."
      ],
      "metadata": {
        "id": "LknoaXX2wtiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import torch\n",
        "import utils\n",
        "They are Python imports. torch is the main library for PyTorch, which YOLOv5 uses for model training and inference, and utils is a module within YOLOv5 containing utility functions."
      ],
      "metadata": {
        "id": "5wqk38RUqJb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "display = utils.notebook_init()  # checks\n",
        "This line calls notebook_init() from the utils module. It‚Äôs used to set up display options and perform environment checks, providing helpful information if any prerequisites are missing."
      ],
      "metadata": {
        "id": "5N8yXdguqaql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQZlZT3VCJDI",
        "outputId": "6a772257-6621-4d27-e017-c43b404e6173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from google.colab import drive\n",
        "The line imports the drive module from google.colab, which allows the user to access Google Drive within Colab."
      ],
      "metadata": {
        "id": "8C-cxr_5qmny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "drive.mount('/content/drive')\n",
        "This command mounts the Google Drive to a folder called /content/drive in the Colab file system. When the colab has been run, Google Colab will ask for permission to access the Drive."
      ],
      "metadata": {
        "id": "n4pik5qVqzwq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Detect\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
        "\n",
        "```shell\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image\n",
        "                          vid.mp4  # video\n",
        "                          screen  # screenshot\n",
        "                          path/  # directory\n",
        "                         'path/*.jpg'  # glob\n",
        "                         'https://youtu.be/LNwODJXcvt4'  # YouTube\n",
        "                         'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284ef04b-1596-412f-88f6-948828dd2b49"
      },
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n",
        "# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 üöÄ v7.0-136-g71244ae Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 24.5MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "image 1/2 /content/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 41.5ms\n",
            "image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 60.0ms\n",
            "Speed: 0.5ms pre-process, 50.8ms inference, 37.7ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/127574988-6a558aa1-d268-44b9-bf6b-62d4c605cc72.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Validate\n",
        "Validate a model's accuracy on the [COCO](https://cocodataset.org/#home) dataset's `val` or `test` splits. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SARcUeGEDS_7",
        "outputId": "e3da4eba-7e72-47c6-988e-bb083a996a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The installation of the Library datasets, it is used for designing and handling large datasets and provide many popular datasets for data processing etc."
      ],
      "metadata": {
        "id": "j2yvwnVmrSx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pyarrow datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgEcmPmqDspc",
        "outputId": "bbe35feb-41a4-4c3e-cfb0-e72ae51e216b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (18.0.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing a pyarrow is neccessary for for handling data in Apache Arrow format, which is optimized for high-performance data interchange. Apache Arrow is useful for efficient data processing and serialization, making it faster to load and save data, especially for large datasets."
      ],
      "metadata": {
        "id": "QP9ebGOxrqd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"garythung/trashnet\")"
      ],
      "metadata": {
        "id": "davkuy0wD27P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from datasets import load_dataset\n",
        "This imports the load_dataset function from the datasets library. load_dataset is a versatile function that allows the user to load datasets directly from Hugging Face‚Äôs hub or from local files."
      ],
      "metadata": {
        "id": "0sprJC0-tZ7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ds = load_dataset(\"garythung/trashnet\")\n",
        "\n",
        "This line loads the TrashNet dataset, a dataset of images for waste classification, hosted under the Hugging Face user garythung."
      ],
      "metadata": {
        "id": "K6jnjtrotsJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install yolov5\n",
        "\n",
        "\n",
        "from yolov5.models.yolo import Model\n",
        "\n",
        "\n",
        "\n",
        "model = Model('yolov5/models/yolov5s.yaml')\n",
        "\n",
        "\n",
        "\n",
        "model.conf = 0.30\n",
        "model.iou = 0.40\n",
        "model.agnostic = False\n",
        "model.multi_label = False\n",
        "model.max_det = 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GCL2CWxJLJx",
        "outputId": "97d17856-d12d-4057-9c2b-462a0b7a1390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17036, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 17036 (delta 6), reused 8 (delta 4), pack-reused 17022 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17036/17036), 15.63 MiB | 8.78 MiB/s, done.\n",
            "Resolving deltas: 100% (11696/11696), done.\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: yolov5 in /usr/local/lib/python3.10/dist-packages (7.0.13)\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from yolov5) (3.1.43)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from yolov5) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from yolov5) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from yolov5) (4.9.0.80)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from yolov5) (10.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from yolov5) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from yolov5) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from yolov5) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from yolov5) (1.13.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from yolov5) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from yolov5) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from yolov5) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from yolov5) (4.66.5)\n",
            "Requirement already satisfied: ultralytics>=8.0.100 in /usr/local/lib/python3.10/dist-packages (from yolov5) (8.3.28)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from yolov5) (2.17.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from yolov5) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from yolov5) (0.13.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from yolov5) (71.0.4)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from yolov5) (0.7.0)\n",
            "Requirement already satisfied: boto3>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from yolov5) (1.35.56)\n",
            "Requirement already satisfied: sahi>=0.11.10 in /usr/local/lib/python3.10/dist-packages (from yolov5) (0.11.18)\n",
            "Requirement already satisfied: huggingface-hub>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from yolov5) (0.24.7)\n",
            "Requirement already satisfied: roboflow>=0.2.29 in /usr/local/lib/python3.10/dist-packages (from yolov5) (1.1.49)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.56 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.19.1->yolov5) (1.35.56)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.19.1->yolov5) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.19.1->yolov5) (0.10.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->yolov5) (4.0.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.12.0->yolov5) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.12.0->yolov5) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.12.0->yolov5) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.12.0->yolov5) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->yolov5) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->yolov5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->yolov5) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->yolov5) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->yolov5) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->yolov5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->yolov5) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->yolov5) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->yolov5) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->yolov5) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->yolov5) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->yolov5) (2024.8.30)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow>=0.2.29->yolov5) (4.10.0.84)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow>=0.2.29->yolov5) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow>=0.2.29->yolov5) (1.16.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow>=0.2.29->yolov5) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow>=0.2.29->yolov5) (1.2.0)\n",
            "Requirement already satisfied: shapely>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from sahi>=0.11.10->yolov5) (2.0.6)\n",
            "Requirement already satisfied: pybboxes==0.1.6 in /usr/local/lib/python3.10/dist-packages (from sahi>=0.11.10->yolov5) (0.1.6)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from sahi>=0.11.10->yolov5) (3.1.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sahi>=0.11.10->yolov5) (8.1.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->yolov5) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->yolov5) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->yolov5) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->yolov5) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->yolov5) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->yolov5) (3.0.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->yolov5) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->yolov5) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->yolov5) (3.1.4)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.100->yolov5) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.100->yolov5) (2.0.11)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->yolov5) (2.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->yolov5) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->yolov5) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->yolov5) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
            "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n",
            "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
            "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n",
            "  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n",
            " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
            " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  yolov5.models.yolo.Detect               [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "\n",
        "This command clones the YOLOv5 GitHub repository into your environment, giving the access to the YOLOv5 code, including pre-trained models and configuration files."
      ],
      "metadata": {
        "id": "Ah7toI0zt4I6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "\n",
        "This command installs PyTorch along with torchvision and torchaudio using precompiled CUDA 11.8 binaries"
      ],
      "metadata": {
        "id": "cmKEpb7zvvTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install yolov5\n",
        "\n",
        "This command installs the YOLOv5 package itself, which simplifies access to YOLOv5 models and functionalities."
      ],
      "metadata": {
        "id": "bQZr1eqhv4xc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from yolov5.models.yolo import Model\n",
        "\n",
        "This imports the Model class from YOLOv5, allows to create and customize a YOLO model instance."
      ],
      "metadata": {
        "id": "jWVZ8o2SwAXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model = Model('yolov5/models/yolov5s.yaml')\n",
        "\n",
        "\n",
        "This line initializes a YOLOv5 model using the yolov5s.yaml configuration file. This YAML file defines the architecture, including layer configurations and model-specific parameters, of YOLOv5‚Äôs small (s) variant, which is generally faster but less accurate compared to larger models like yolov5m or yolov5l.\n",
        "\n"
      ],
      "metadata": {
        "id": "P82PdwPnwPKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.conf = 0.30        # Confidence threshold for predictions\n",
        "model.iou = 0.40         # Intersection Over Union (IoU) threshold for NMS\n",
        "model.agnostic = False   # Class-agnostic NMS (non-maximum suppression)\n",
        "model.multi_label = False  # Whether to allow multi-label detection\n",
        "model.max_det = 1000     # Maximum number of detections per image\n",
        "\n",
        "\n",
        "\n",
        "1. model.conf: Sets a confidence threshold of 0.30, meaning predictions with confidence below 30% will be ignored.\n",
        "2. model.iou: Sets the IoU threshold for Non-Maximum Suppression (NMS), which is used to remove overlapping bounding boxes.\n",
        "3. model.agnostic: If True, NMS would ignore class differences, treating all classes equally when filtering.\n",
        "4. model.multi_label: If True, allows multiple labels per bounding box.\n",
        "5. model.max_det: Limits the number of detected objects per image to 1000."
      ],
      "metadata": {
        "id": "0R9Fbuq1wnc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'"
      ],
      "metadata": {
        "id": "dbW4AqL1JUIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By assigning the URL to img, you can later use this variable to load the image directly into YOLOv5 or any image processing library. This approach avoids having to manually download and load the image."
      ],
      "metadata": {
        "id": "N-rqY7v0xEyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from yolov5.models.yolo import Model\n",
        "\n",
        "\n",
        "model = Model('yolov5/models/yolov5s.yaml')\n",
        "\n",
        "\n",
        "img_url = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'\n",
        "\n",
        "\n",
        "model_inference = torch.hub.load('ultralytics/yolov5', 'yolov5s', source='github')\n",
        "\n",
        "\n",
        "results = model_inference(img_url)\n",
        "\n",
        "\n",
        "results.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_hKCqKRJ9RZ",
        "outputId": "ce8f0df9-cc99-41f2-89a3-b0f6c51692a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
            "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n",
            "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
            "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n",
            "  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n",
            " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
            " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  yolov5.models.yolo.Detect               [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 üöÄ v7.0-381-g15c40626 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.1M/14.1M [00:00<00:00, 32.7MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "WARNING ‚ö†Ô∏è NMS time limit 0.550s exceeded\n",
            "image 1/1: 720x1280 2 persons, 2 ties\n",
            "Speed: 944.8ms pre-process, 112.2ms inference, 845.1ms NMS per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import torch\n",
        "from yolov5.models.yolo import Model\n",
        "\n",
        "\n",
        "Imports PyTorch for model inference and Model from YOLOv5, allows the user to create or configure YOLOv5 models."
      ],
      "metadata": {
        "id": "wmTaIJ9_xnTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model = Model('yolov5/models/yolov5s.yaml')\n",
        "\n",
        "\n",
        "This line loads the YOLOv5s model architecture defined in the yolov5s.yaml configuration file."
      ],
      "metadata": {
        "id": "RbZHjH-8xy8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "img_url = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'\n",
        "\n",
        "\n",
        "This variable contains the URL for an example image that will be used for model inference."
      ],
      "metadata": {
        "id": "j1YNqE0Nx64A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_inference = torch.hub.load('ultralytics/yolov5', 'yolov5s', source='github')\n",
        "\n",
        "\n",
        "The torch.hub.load function loads a pre-trained YOLOv5s model from GitHub (source: 'github'). This model is set up for inference directly and is pre-trained on the COCO dataset, enabling it to detect various objects out-of-the-box."
      ],
      "metadata": {
        "id": "2bqJWxAIy22x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "results = model_inference(img_url)\n",
        "\n",
        "\n",
        "This line applies the loaded YOLOv5 model on the img_url image, detecting objects in it. The result is stored in results, which contains detection data (like bounding boxes, confidence scores, and class labels)."
      ],
      "metadata": {
        "id": "Gi-oNyqFy-6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "results.print()\n",
        "\n",
        "\n",
        "The results.print() function outputs the detection results to the console, showing details like object classes, confidence scores, and coordinates of detected bounding boxes."
      ],
      "metadata": {
        "id": "DtDXVHL0zGYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from yolov5.models.yolo import Model\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model = Model('yolov5/models/yolov5s.yaml')\n",
        "\n",
        "\n",
        "img_url = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'\n",
        "\n",
        "\n",
        "response = requests.get(img_url, stream=True)\n",
        "response.raise_for_status()\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "stride = model.stride.max()\n",
        "width, height = image.size\n",
        "new_width = int(width // stride * stride)\n",
        "new_height = int(height // stride * stride)\n",
        "\n",
        "\n",
        "image = image.resize((new_width, new_height))\n",
        "\n",
        "\n",
        "\n",
        "image_tensor = torch.from_numpy(np.array(image)).float() / 255.0\n",
        "\n",
        "image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "\n",
        "results = model(image_tensor, augment=False)\n",
        "\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDreqA3rKr3t",
        "outputId": "4e7f5679-9a31-4da2-c0d7-5396b7704a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
            "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n",
            "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
            "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n",
            "  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n",
            " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
            " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  yolov5.models.yolo.Detect               [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[[[[ 3.92558e-02, -9.79096e-02, -2.12568e-02,  ..., -4.88824e+00, -4.88392e+00, -4.80181e+00],\n",
            "           [-6.77231e-02, -3.63810e-02, -6.52337e-02,  ..., -4.90748e+00, -4.91735e+00, -4.86554e+00],\n",
            "           [-1.97064e-02, -2.33100e-02, -1.40670e-02,  ..., -4.88528e+00, -4.92844e+00, -4.84665e+00],\n",
            "           ...,\n",
            "           [ 2.69638e-02,  3.97096e-02, -1.14383e-01,  ..., -4.81806e+00, -4.93967e+00, -4.89413e+00],\n",
            "           [ 1.89914e-02,  5.16368e-02, -1.15835e-01,  ..., -4.81091e+00, -4.98127e+00, -4.88536e+00],\n",
            "           [ 2.39427e-02,  1.10680e-02, -1.15320e-01,  ..., -4.83265e+00, -4.93144e+00, -4.84498e+00]],\n",
            "\n",
            "          [[ 8.45132e-02, -6.92632e-02, -2.61629e-02,  ..., -4.86573e+00, -4.80128e+00, -4.77845e+00],\n",
            "           [-4.71729e-02, -4.12299e-03, -4.14647e-02,  ..., -4.92053e+00, -4.88760e+00, -4.84113e+00],\n",
            "           [-2.17457e-02,  3.72251e-03,  1.96338e-02,  ..., -4.87935e+00, -4.91237e+00, -4.82400e+00],\n",
            "           ...,\n",
            "           [ 8.03570e-03,  2.30732e-02, -7.06724e-02,  ..., -4.90164e+00, -4.90067e+00, -4.85484e+00],\n",
            "           [ 4.07450e-03,  8.21554e-02, -1.27224e-01,  ..., -4.86865e+00, -4.95556e+00, -4.84560e+00],\n",
            "           [-3.37825e-02,  2.15341e-02, -1.23133e-01,  ..., -4.98248e+00, -4.84962e+00, -4.79252e+00]],\n",
            "\n",
            "          [[ 8.45707e-02, -8.83442e-02, -3.69766e-02,  ..., -4.90935e+00, -4.79048e+00, -4.79675e+00],\n",
            "           [-6.71059e-02, -1.80542e-02, -5.64511e-02,  ..., -4.90764e+00, -4.87760e+00, -4.86572e+00],\n",
            "           [-3.10129e-02, -3.37466e-02,  3.10104e-03,  ..., -4.93740e+00, -4.89866e+00, -4.86049e+00],\n",
            "           ...,\n",
            "           [ 4.77265e-02, -4.28157e-02, -4.97452e-02,  ..., -4.88347e+00, -4.89235e+00, -4.81113e+00],\n",
            "           [ 6.19841e-03,  3.21061e-03, -1.05019e-01,  ..., -4.82803e+00, -4.93560e+00, -4.81264e+00],\n",
            "           [-7.54828e-02, -1.18940e-01, -1.29349e-01,  ..., -5.01607e+00, -4.75147e+00, -4.74376e+00]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-5.50471e-03, -9.44961e-02, -5.01489e-02,  ..., -4.88279e+00, -4.88144e+00, -4.85168e+00],\n",
            "           [-6.31703e-02, -5.88576e-02, -7.70035e-02,  ..., -4.89174e+00, -4.93320e+00, -4.83086e+00],\n",
            "           [-5.97308e-02, -3.18137e-02, -3.00725e-02,  ..., -4.89370e+00, -4.94191e+00, -4.83390e+00],\n",
            "           ...,\n",
            "           [ 2.57320e-02,  1.11807e-01, -4.83390e-02,  ..., -4.76051e+00, -5.06656e+00, -4.82578e+00],\n",
            "           [ 4.65584e-02,  1.00996e-01, -2.05015e-02,  ..., -4.76469e+00, -5.04265e+00, -4.81195e+00],\n",
            "           [ 7.61715e-02,  7.64029e-02,  2.76635e-03,  ..., -4.82880e+00, -4.98766e+00, -4.79749e+00]],\n",
            "\n",
            "          [[ 1.69139e-02, -8.84311e-02, -5.39942e-02,  ..., -4.85054e+00, -4.87241e+00, -4.83507e+00],\n",
            "           [-4.67983e-02, -4.91753e-02, -1.02279e-01,  ..., -4.86183e+00, -4.90693e+00, -4.83871e+00],\n",
            "           [-4.72166e-02, -2.80726e-02, -7.77443e-02,  ..., -4.85398e+00, -4.91099e+00, -4.83269e+00],\n",
            "           ...,\n",
            "           [ 1.55619e-02,  8.05471e-02, -6.28681e-02,  ..., -4.75710e+00, -5.04188e+00, -4.84266e+00],\n",
            "           [ 4.80430e-02,  7.19620e-02, -5.83959e-02,  ..., -4.72344e+00, -5.03158e+00, -4.85274e+00],\n",
            "           [ 7.34873e-02,  7.91931e-02, -5.79101e-02,  ..., -4.77273e+00, -4.95808e+00, -4.82263e+00]],\n",
            "\n",
            "          [[ 7.92220e-03, -2.92369e-02, -3.46001e-02,  ..., -4.82920e+00, -4.87705e+00, -4.86673e+00],\n",
            "           [-1.97183e-02,  1.72105e-02, -6.17998e-02,  ..., -4.81821e+00, -4.91841e+00, -4.86491e+00],\n",
            "           [-5.06055e-02,  1.60472e-02, -3.69251e-02,  ..., -4.85933e+00, -4.92863e+00, -4.83775e+00],\n",
            "           ...,\n",
            "           [ 1.23611e-02,  5.36816e-02, -3.62845e-02,  ..., -4.80017e+00, -5.03656e+00, -4.84072e+00],\n",
            "           [ 5.10133e-03,  2.03381e-02, -6.03433e-02,  ..., -4.79895e+00, -5.00834e+00, -4.85077e+00],\n",
            "           [ 1.57667e-02,  3.63100e-02, -5.62501e-02,  ..., -4.80051e+00, -4.99832e+00, -4.79419e+00]]],\n",
            "\n",
            "\n",
            "         [[[ 1.08807e-01,  1.53937e-01,  8.43285e-02,  ..., -4.79564e+00, -4.91696e+00, -4.84556e+00],\n",
            "           [ 8.18951e-02,  1.46089e-01,  3.59373e-02,  ..., -4.74616e+00, -4.93151e+00, -4.77383e+00],\n",
            "           [ 8.23459e-02,  1.16378e-01,  5.25373e-02,  ..., -4.73253e+00, -4.92707e+00, -4.80077e+00],\n",
            "           ...,\n",
            "           [ 1.09108e-01,  2.12459e-01,  5.01967e-02,  ..., -4.73843e+00, -4.86265e+00, -4.78174e+00],\n",
            "           [ 9.11843e-02,  2.18579e-01,  3.26290e-02,  ..., -4.73661e+00, -4.91253e+00, -4.80400e+00],\n",
            "           [ 1.13892e-01,  2.41119e-01,  6.38049e-02,  ..., -4.73243e+00, -4.91084e+00, -4.81395e+00]],\n",
            "\n",
            "          [[ 9.15517e-02,  1.27823e-01,  1.00017e-01,  ..., -4.74306e+00, -4.80706e+00, -4.84200e+00],\n",
            "           [ 2.74618e-02,  1.25076e-01,  8.68081e-02,  ..., -4.70823e+00, -4.90263e+00, -4.79753e+00],\n",
            "           [ 3.54225e-02,  1.10320e-01,  7.85978e-02,  ..., -4.70071e+00, -4.90027e+00, -4.86068e+00],\n",
            "           ...,\n",
            "           [ 8.43115e-02,  2.08830e-01,  4.59417e-02,  ..., -4.72378e+00, -4.90211e+00, -4.75052e+00],\n",
            "           [ 7.04113e-02,  2.19345e-01,  1.49360e-02,  ..., -4.71614e+00, -4.93049e+00, -4.76819e+00],\n",
            "           [ 4.99249e-02,  2.72059e-01,  2.47380e-02,  ..., -4.78287e+00, -4.91668e+00, -4.79427e+00]],\n",
            "\n",
            "          [[ 5.79654e-02,  1.52515e-01,  9.00009e-02,  ..., -4.74616e+00, -4.82109e+00, -4.80425e+00],\n",
            "           [ 2.10193e-02,  1.32739e-01,  9.52688e-02,  ..., -4.68825e+00, -4.88991e+00, -4.77841e+00],\n",
            "           [ 2.20179e-02,  1.28986e-01,  7.85117e-02,  ..., -4.69751e+00, -4.87820e+00, -4.85846e+00],\n",
            "           ...,\n",
            "           [ 1.37796e-01,  2.28146e-01,  9.92482e-02,  ..., -4.70468e+00, -4.86419e+00, -4.75801e+00],\n",
            "           [ 9.66167e-02,  2.18624e-01, -1.20978e-03,  ..., -4.69297e+00, -4.88828e+00, -4.77049e+00],\n",
            "           [ 9.28109e-02,  2.75590e-01, -4.05162e-02,  ..., -4.78968e+00, -4.86093e+00, -4.75697e+00]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 4.17142e-02,  1.84999e-01,  7.08212e-02,  ..., -4.75456e+00, -4.86715e+00, -4.86564e+00],\n",
            "           [ 3.86556e-02,  1.76732e-01,  5.71320e-02,  ..., -4.72288e+00, -4.87792e+00, -4.84399e+00],\n",
            "           [ 1.34308e-02,  1.68270e-01,  6.36949e-02,  ..., -4.71799e+00, -4.88677e+00, -4.86412e+00],\n",
            "           ...,\n",
            "           [ 6.48604e-02,  1.55570e-01,  5.55179e-02,  ..., -4.66389e+00, -4.93386e+00, -4.81798e+00],\n",
            "           [ 1.13547e-01,  1.51657e-01,  5.79647e-02,  ..., -4.65987e+00, -4.94842e+00, -4.87084e+00],\n",
            "           [ 1.00169e-01,  1.33211e-01,  9.48822e-02,  ..., -4.67926e+00, -4.96048e+00, -4.85196e+00]],\n",
            "\n",
            "          [[ 3.59667e-02,  1.83041e-01,  6.52697e-02,  ..., -4.77849e+00, -4.85442e+00, -4.85668e+00],\n",
            "           [ 3.88429e-02,  1.58026e-01,  5.27210e-02,  ..., -4.73343e+00, -4.87389e+00, -4.85821e+00],\n",
            "           [ 1.14374e-02,  1.80486e-01,  4.73795e-02,  ..., -4.73785e+00, -4.88355e+00, -4.88548e+00],\n",
            "           ...,\n",
            "           [ 5.03071e-02,  1.34673e-01,  4.59584e-02,  ..., -4.69505e+00, -4.90751e+00, -4.85733e+00],\n",
            "           [ 5.61576e-02,  1.52571e-01,  3.56448e-02,  ..., -4.67630e+00, -4.90748e+00, -4.87856e+00],\n",
            "           [ 6.85744e-02,  1.66188e-01,  6.42964e-02,  ..., -4.71290e+00, -4.90821e+00, -4.85151e+00]],\n",
            "\n",
            "          [[ 1.14726e-02,  1.67537e-01,  5.94684e-02,  ..., -4.77814e+00, -4.85493e+00, -4.83314e+00],\n",
            "           [-4.66021e-02,  1.91575e-01,  7.23544e-02,  ..., -4.73811e+00, -4.85313e+00, -4.84430e+00],\n",
            "           [-5.12314e-02,  1.75498e-01,  6.02017e-02,  ..., -4.75080e+00, -4.84939e+00, -4.86594e+00],\n",
            "           ...,\n",
            "           [ 8.12180e-02,  1.59520e-01,  6.81172e-02,  ..., -4.68216e+00, -4.91212e+00, -4.83657e+00],\n",
            "           [ 1.06311e-01,  1.73517e-01,  5.08527e-02,  ..., -4.69174e+00, -4.93370e+00, -4.88636e+00],\n",
            "           [ 1.33850e-01,  1.82140e-01,  5.27792e-02,  ..., -4.67401e+00, -4.96843e+00, -4.87317e+00]]],\n",
            "\n",
            "\n",
            "         [[[-4.86074e-02, -1.40030e-01,  2.50180e-03,  ..., -4.82961e+00, -4.80176e+00, -4.93139e+00],\n",
            "           [-5.36428e-02, -9.79783e-02, -4.16951e-03,  ..., -4.81155e+00, -4.82149e+00, -4.89203e+00],\n",
            "           [-1.33819e-02, -1.36508e-01,  2.60981e-02,  ..., -4.87674e+00, -4.79326e+00, -4.92439e+00],\n",
            "           ...,\n",
            "           [-3.62060e-02, -9.23112e-02, -1.54280e-02,  ..., -4.91917e+00, -4.78993e+00, -4.92632e+00],\n",
            "           [-4.06250e-02, -1.28017e-01, -2.85022e-03,  ..., -4.93223e+00, -4.79847e+00, -4.97382e+00],\n",
            "           [-4.39781e-02, -1.26945e-01,  3.09322e-02,  ..., -4.93099e+00, -4.80822e+00, -5.00065e+00]],\n",
            "\n",
            "          [[-8.22291e-02, -1.49073e-01, -1.33720e-02,  ..., -4.89281e+00, -4.81347e+00, -4.92574e+00],\n",
            "           [-5.49148e-02, -1.11309e-01,  1.93660e-02,  ..., -4.89649e+00, -4.79912e+00, -4.91460e+00],\n",
            "           [-1.15549e-02, -1.44782e-01,  6.37521e-02,  ..., -4.95194e+00, -4.77336e+00, -4.94032e+00],\n",
            "           ...,\n",
            "           [-6.73012e-02, -6.41308e-02,  1.00986e-02,  ..., -4.93340e+00, -4.80046e+00, -4.90630e+00],\n",
            "           [-6.57360e-02, -1.02957e-01, -1.71172e-02,  ..., -4.94472e+00, -4.78043e+00, -4.96682e+00],\n",
            "           [-4.10049e-02, -7.92370e-02,  2.12343e-02,  ..., -4.94060e+00, -4.85360e+00, -4.98635e+00]],\n",
            "\n",
            "          [[-9.88286e-02, -1.40401e-01, -3.82979e-02,  ..., -4.83679e+00, -4.83194e+00, -4.94579e+00],\n",
            "           [-6.12007e-02, -1.28830e-01,  2.87922e-02,  ..., -4.88187e+00, -4.78357e+00, -4.96691e+00],\n",
            "           [-5.17479e-02, -1.42939e-01,  1.92091e-02,  ..., -4.93069e+00, -4.75957e+00, -4.94140e+00],\n",
            "           ...,\n",
            "           [-8.87505e-02, -1.43493e-01, -3.14066e-02,  ..., -4.87835e+00, -4.74746e+00, -4.94564e+00],\n",
            "           [-1.00425e-01, -1.43027e-01, -3.68069e-02,  ..., -4.90877e+00, -4.77251e+00, -5.04155e+00],\n",
            "           [-9.13985e-02, -1.25182e-01, -1.19801e-02,  ..., -4.89818e+00, -4.87803e+00, -5.03124e+00]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-9.88641e-02, -1.39336e-01, -1.25918e-02,  ..., -4.87191e+00, -4.80722e+00, -4.90555e+00],\n",
            "           [-1.01852e-01, -1.36440e-01,  5.97394e-02,  ..., -4.90016e+00, -4.77602e+00, -4.94290e+00],\n",
            "           [-5.57049e-02, -1.42560e-01,  6.05434e-02,  ..., -4.94864e+00, -4.75968e+00, -4.96070e+00],\n",
            "           ...,\n",
            "           [ 8.04161e-02, -1.57894e-01,  5.27823e-02,  ..., -4.84406e+00, -4.73755e+00, -5.03011e+00],\n",
            "           [ 7.41946e-02, -1.88938e-01, -1.59256e-02,  ..., -4.84346e+00, -4.73352e+00, -5.03706e+00],\n",
            "           [ 8.17076e-02, -1.92005e-01,  2.86269e-02,  ..., -4.83172e+00, -4.77185e+00, -5.01036e+00]],\n",
            "\n",
            "          [[-1.04038e-01, -1.37340e-01, -6.07010e-03,  ..., -4.85386e+00, -4.83271e+00, -4.90843e+00],\n",
            "           [-1.18092e-01, -1.51160e-01,  5.97533e-02,  ..., -4.89204e+00, -4.80703e+00, -4.95911e+00],\n",
            "           [-8.38478e-02, -1.45814e-01,  8.18151e-02,  ..., -4.90355e+00, -4.80193e+00, -4.97535e+00],\n",
            "           ...,\n",
            "           [ 5.44186e-02, -1.83543e-01,  5.74858e-02,  ..., -4.85091e+00, -4.76501e+00, -5.01798e+00],\n",
            "           [ 5.31660e-02, -2.17923e-01,  2.26866e-02,  ..., -4.83842e+00, -4.77377e+00, -5.04649e+00],\n",
            "           [ 2.85386e-02, -2.02559e-01,  1.44147e-02,  ..., -4.87686e+00, -4.79886e+00, -5.02434e+00]],\n",
            "\n",
            "          [[-7.66730e-02, -1.36522e-01, -3.55570e-02,  ..., -4.87882e+00, -4.80420e+00, -4.92306e+00],\n",
            "           [-7.97924e-02, -1.84687e-01, -1.77449e-03,  ..., -4.90855e+00, -4.77081e+00, -4.98819e+00],\n",
            "           [-4.34909e-02, -1.55987e-01,  2.94602e-03,  ..., -4.90619e+00, -4.77176e+00, -4.97234e+00],\n",
            "           ...,\n",
            "           [ 7.75541e-02, -1.83494e-01, -2.39977e-02,  ..., -4.81686e+00, -4.75565e+00, -5.01260e+00],\n",
            "           [ 6.10228e-02, -2.12704e-01, -7.48393e-02,  ..., -4.80310e+00, -4.75805e+00, -5.01532e+00],\n",
            "           [ 6.61044e-02, -2.26263e-01, -6.75753e-02,  ..., -4.80667e+00, -4.75495e+00, -5.08679e+00]]]]], grad_fn=<CloneBackward0>), tensor([[[[[ 1.06844e-01,  1.56615e-01, -8.04434e-02,  ..., -4.80279e+00, -4.99854e+00, -4.92618e+00],\n",
            "           [ 8.53439e-02,  1.10800e-01, -9.95568e-02,  ..., -4.79853e+00, -4.99797e+00, -4.91790e+00],\n",
            "           [ 7.64283e-02,  1.06829e-01, -1.13960e-01,  ..., -4.80113e+00, -4.99695e+00, -4.91182e+00],\n",
            "           ...,\n",
            "           [-6.86390e-03,  8.36604e-02,  2.09028e-03,  ..., -4.87659e+00, -4.83216e+00, -4.97107e+00],\n",
            "           [ 3.24791e-02,  8.46794e-02,  1.05628e-02,  ..., -4.84963e+00, -4.88232e+00, -4.99891e+00],\n",
            "           [ 1.31905e-02,  7.56253e-02, -8.46244e-03,  ..., -4.85854e+00, -4.88721e+00, -4.96997e+00]],\n",
            "\n",
            "          [[ 6.81946e-02,  1.84392e-01, -8.81996e-02,  ..., -4.84825e+00, -5.02508e+00, -4.93332e+00],\n",
            "           [ 8.83490e-02,  1.28347e-01, -1.37833e-01,  ..., -4.82858e+00, -5.01510e+00, -4.91005e+00],\n",
            "           [ 7.00708e-02,  1.20083e-01, -1.42194e-01,  ..., -4.82588e+00, -5.01292e+00, -4.90596e+00],\n",
            "           ...,\n",
            "           [-6.80978e-02,  7.85683e-02, -1.95202e-02,  ..., -4.94072e+00, -4.80789e+00, -4.96068e+00],\n",
            "           [-5.31418e-02,  6.78570e-02, -4.61615e-03,  ..., -4.91696e+00, -4.88349e+00, -4.99985e+00],\n",
            "           [-3.52299e-02,  6.31423e-02,  3.07605e-03,  ..., -4.90044e+00, -4.87893e+00, -4.94673e+00]],\n",
            "\n",
            "          [[ 8.02613e-02,  1.65542e-01, -8.21816e-02,  ..., -4.84351e+00, -5.02874e+00, -4.92486e+00],\n",
            "           [ 9.24014e-02,  1.35618e-01, -1.35875e-01,  ..., -4.82032e+00, -5.02461e+00, -4.90926e+00],\n",
            "           [ 7.01060e-02,  1.21499e-01, -1.42725e-01,  ..., -4.81562e+00, -5.01929e+00, -4.90941e+00],\n",
            "           ...,\n",
            "           [-4.40974e-02,  6.96278e-02, -5.68383e-02,  ..., -4.93469e+00, -4.80709e+00, -4.96120e+00],\n",
            "           [-3.64528e-02,  6.87891e-02, -1.12435e-02,  ..., -4.93983e+00, -4.89801e+00, -4.99845e+00],\n",
            "           [-2.63785e-02,  7.19814e-02,  3.70498e-03,  ..., -4.93748e+00, -4.88441e+00, -4.94505e+00]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 9.33861e-02,  1.80979e-01, -8.13841e-02,  ..., -4.82690e+00, -5.00368e+00, -4.90194e+00],\n",
            "           [ 9.04612e-02,  1.44077e-01, -1.40101e-01,  ..., -4.81863e+00, -5.00388e+00, -4.90390e+00],\n",
            "           [ 8.10980e-02,  1.27987e-01, -1.38256e-01,  ..., -4.81313e+00, -5.00019e+00, -4.90566e+00],\n",
            "           ...,\n",
            "           [ 5.31824e-02,  1.67838e-01, -5.37532e-02,  ..., -4.84466e+00, -4.86670e+00, -4.96298e+00],\n",
            "           [ 6.12056e-02,  1.72101e-01, -1.33218e-01,  ..., -4.92825e+00, -4.84730e+00, -4.90300e+00],\n",
            "           [ 4.69331e-02,  1.07943e-01, -8.97378e-02,  ..., -4.88634e+00, -4.84700e+00, -4.91856e+00]],\n",
            "\n",
            "          [[ 9.23754e-02,  1.71858e-01, -7.46258e-02,  ..., -4.83719e+00, -5.00121e+00, -4.90893e+00],\n",
            "           [ 9.18514e-02,  1.48682e-01, -1.30875e-01,  ..., -4.82488e+00, -5.00563e+00, -4.90555e+00],\n",
            "           [ 9.11617e-02,  1.39080e-01, -1.29556e-01,  ..., -4.82633e+00, -4.99368e+00, -4.90920e+00],\n",
            "           ...,\n",
            "           [ 6.84824e-02,  1.64304e-01, -9.29563e-02,  ..., -4.83436e+00, -4.85577e+00, -4.92106e+00],\n",
            "           [ 4.97485e-02,  1.70168e-01, -1.42226e-01,  ..., -4.94348e+00, -4.85946e+00, -4.88222e+00],\n",
            "           [ 4.81279e-02,  1.22675e-01, -9.80667e-02,  ..., -4.91575e+00, -4.83319e+00, -4.88768e+00]],\n",
            "\n",
            "          [[ 9.53055e-02,  1.36500e-01, -9.23332e-02,  ..., -4.85573e+00, -4.95971e+00, -4.93006e+00],\n",
            "           [ 7.73421e-02,  1.32462e-01, -1.22194e-01,  ..., -4.85321e+00, -4.96647e+00, -4.91864e+00],\n",
            "           [ 6.42587e-02,  1.26917e-01, -1.24153e-01,  ..., -4.85834e+00, -4.96373e+00, -4.91816e+00],\n",
            "           ...,\n",
            "           [ 6.58364e-02,  1.18741e-01, -8.30994e-02,  ..., -4.81418e+00, -4.84843e+00, -4.96012e+00],\n",
            "           [ 5.05748e-02,  1.57554e-01, -1.09067e-01,  ..., -4.91487e+00, -4.86084e+00, -4.94370e+00],\n",
            "           [ 4.98075e-02,  1.35596e-01, -9.04928e-02,  ..., -4.90139e+00, -4.86558e+00, -4.91530e+00]]],\n",
            "\n",
            "\n",
            "         [[[ 6.11967e-02, -1.76962e-02,  6.11667e-03,  ..., -4.84739e+00, -4.85202e+00, -4.93298e+00],\n",
            "           [ 4.38479e-02,  1.56181e-02,  4.89604e-03,  ..., -4.79688e+00, -4.86850e+00, -4.92146e+00],\n",
            "           [ 4.53851e-02,  1.61731e-02, -4.97387e-03,  ..., -4.81128e+00, -4.87321e+00, -4.91980e+00],\n",
            "           ...,\n",
            "           [ 9.50864e-02, -1.39742e-01, -9.73144e-02,  ..., -4.86288e+00, -4.83568e+00, -4.99204e+00],\n",
            "           [ 9.07801e-02, -1.14933e-01, -9.22061e-02,  ..., -4.83878e+00, -4.86996e+00, -4.93640e+00],\n",
            "           [ 7.86060e-02, -6.71138e-02, -7.82105e-02,  ..., -4.84229e+00, -4.85687e+00, -4.92811e+00]],\n",
            "\n",
            "          [[ 3.41956e-02,  9.27663e-04,  1.61368e-03,  ..., -4.86810e+00, -4.86897e+00, -4.93630e+00],\n",
            "           [ 9.47881e-03,  4.11215e-02,  6.31519e-03,  ..., -4.81911e+00, -4.91522e+00, -4.93651e+00],\n",
            "           [ 2.01237e-02,  3.24266e-02, -9.21586e-03,  ..., -4.82566e+00, -4.91089e+00, -4.93604e+00],\n",
            "           ...,\n",
            "           [ 9.03265e-02, -9.16153e-02, -8.21020e-02,  ..., -4.89094e+00, -4.82932e+00, -4.97400e+00],\n",
            "           [ 8.34100e-02, -7.97939e-02, -6.41803e-02,  ..., -4.86617e+00, -4.87776e+00, -4.96961e+00],\n",
            "           [ 6.34381e-02, -5.00902e-02, -5.40689e-02,  ..., -4.91227e+00, -4.85641e+00, -4.90349e+00]],\n",
            "\n",
            "          [[ 4.30621e-02, -2.62748e-02,  5.88498e-03,  ..., -4.86181e+00, -4.87466e+00, -4.93632e+00],\n",
            "           [ 8.80683e-03,  1.84118e-02, -6.23704e-03,  ..., -4.81429e+00, -4.89758e+00, -4.93461e+00],\n",
            "           [ 2.34311e-02,  4.39822e-03, -1.52611e-02,  ..., -4.82105e+00, -4.90071e+00, -4.94507e+00],\n",
            "           ...,\n",
            "           [ 7.36517e-02, -9.71970e-02, -6.90226e-02,  ..., -4.89467e+00, -4.83698e+00, -4.98844e+00],\n",
            "           [ 5.65305e-02, -8.41202e-02, -7.44621e-02,  ..., -4.86491e+00, -4.89230e+00, -4.96001e+00],\n",
            "           [ 4.17183e-02, -9.59505e-02, -6.85008e-02,  ..., -4.92697e+00, -4.84832e+00, -4.89049e+00]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 3.52209e-02, -3.25461e-02,  6.76671e-03,  ..., -4.85843e+00, -4.87041e+00, -4.92384e+00],\n",
            "           [ 2.20658e-02, -9.52356e-03,  1.15349e-02,  ..., -4.82290e+00, -4.89989e+00, -4.93714e+00],\n",
            "           [ 2.13875e-02, -1.74800e-02, -5.98942e-03,  ..., -4.82720e+00, -4.90009e+00, -4.93443e+00],\n",
            "           ...,\n",
            "           [ 6.31077e-02, -1.16829e-01, -8.51315e-02,  ..., -4.83292e+00, -4.90075e+00, -4.95542e+00],\n",
            "           [ 3.31409e-02, -1.35738e-01, -7.70972e-02,  ..., -4.87280e+00, -4.91291e+00, -4.89788e+00],\n",
            "           [ 1.04006e-01, -1.52716e-01, -1.01705e-01,  ..., -4.85370e+00, -4.89909e+00, -4.92030e+00]],\n",
            "\n",
            "          [[ 2.99386e-02, -3.76734e-02,  1.15962e-02,  ..., -4.85211e+00, -4.87555e+00, -4.93380e+00],\n",
            "           [ 2.42482e-02,  5.95883e-04,  5.40704e-03,  ..., -4.81309e+00, -4.89227e+00, -4.93420e+00],\n",
            "           [ 2.38776e-02, -6.60165e-03, -1.22681e-02,  ..., -4.81025e+00, -4.88444e+00, -4.93258e+00],\n",
            "           ...,\n",
            "           [ 2.49203e-02, -1.11055e-01, -4.39928e-02,  ..., -4.80475e+00, -4.90344e+00, -4.93802e+00],\n",
            "           [ 4.05575e-02, -9.19509e-02, -8.09017e-02,  ..., -4.83349e+00, -4.91799e+00, -4.92258e+00],\n",
            "           [ 6.63714e-02, -8.37032e-02, -1.13489e-01,  ..., -4.81513e+00, -4.89272e+00, -4.90645e+00]],\n",
            "\n",
            "          [[ 9.64606e-03, -6.64952e-02, -2.06227e-02,  ..., -4.86026e+00, -4.87322e+00, -4.93552e+00],\n",
            "           [ 7.68059e-03, -5.86571e-02, -4.12269e-02,  ..., -4.84966e+00, -4.88331e+00, -4.94122e+00],\n",
            "           [-3.67994e-03, -6.19896e-02, -5.67705e-02,  ..., -4.83846e+00, -4.88290e+00, -4.94530e+00],\n",
            "           ...,\n",
            "           [ 3.50764e-03, -9.28155e-02, -7.54878e-02,  ..., -4.79503e+00, -4.86181e+00, -4.91595e+00],\n",
            "           [ 1.21533e-03, -8.24462e-02, -9.64340e-02,  ..., -4.82545e+00, -4.85164e+00, -4.90670e+00],\n",
            "           [ 2.46734e-02, -1.10106e-01, -1.15669e-01,  ..., -4.83004e+00, -4.85734e+00, -4.90574e+00]]],\n",
            "\n",
            "\n",
            "         [[[ 1.64591e-02, -8.51866e-02, -2.09137e-01,  ..., -4.84753e+00, -4.86130e+00, -5.01597e+00],\n",
            "           [ 1.53270e-02, -9.30660e-02, -2.09378e-01,  ..., -4.82864e+00, -4.86402e+00, -5.00028e+00],\n",
            "           [ 1.66525e-02, -8.81920e-02, -2.22205e-01,  ..., -4.81907e+00, -4.86092e+00, -5.00409e+00],\n",
            "           ...,\n",
            "           [ 4.99114e-02, -1.23965e-01, -9.63518e-02,  ..., -4.86348e+00, -4.79029e+00, -5.06395e+00],\n",
            "           [ 4.87620e-02, -1.59340e-01, -1.55785e-01,  ..., -4.86557e+00, -4.77931e+00, -5.06133e+00],\n",
            "           [ 3.31020e-02, -1.25049e-01, -1.77090e-01,  ..., -4.82825e+00, -4.75971e+00, -5.01820e+00]],\n",
            "\n",
            "          [[ 7.55982e-03, -8.35283e-02, -2.20754e-01,  ..., -4.85419e+00, -4.86406e+00, -5.06741e+00],\n",
            "           [ 2.06987e-02, -9.15682e-02, -2.74966e-01,  ..., -4.81751e+00, -4.85737e+00, -5.02765e+00],\n",
            "           [ 1.14697e-02, -8.06650e-02, -2.88943e-01,  ..., -4.81762e+00, -4.86036e+00, -5.02926e+00],\n",
            "           ...,\n",
            "           [ 6.20381e-02, -1.07810e-01, -9.09569e-02,  ..., -4.87196e+00, -4.79044e+00, -5.04808e+00],\n",
            "           [ 7.18667e-02, -1.51111e-01, -1.41527e-01,  ..., -4.88076e+00, -4.79449e+00, -5.08385e+00],\n",
            "           [ 8.00901e-02, -6.88988e-02, -1.72204e-01,  ..., -4.81624e+00, -4.77165e+00, -4.99240e+00]],\n",
            "\n",
            "          [[-2.68280e-03, -5.89347e-02, -2.19559e-01,  ..., -4.84421e+00, -4.87267e+00, -5.07168e+00],\n",
            "           [ 4.19624e-03, -8.95922e-02, -2.81167e-01,  ..., -4.81946e+00, -4.86467e+00, -5.02562e+00],\n",
            "           [ 3.44669e-03, -7.41540e-02, -2.97054e-01,  ..., -4.81184e+00, -4.85114e+00, -5.02996e+00],\n",
            "           ...,\n",
            "           [ 5.09492e-02, -1.08322e-01, -8.74084e-02,  ..., -4.84444e+00, -4.80236e+00, -5.02587e+00],\n",
            "           [ 6.92930e-02, -1.56302e-01, -1.40270e-01,  ..., -4.86754e+00, -4.80021e+00, -5.06766e+00],\n",
            "           [ 6.81778e-02, -7.04921e-02, -1.76083e-01,  ..., -4.80890e+00, -4.78205e+00, -4.98226e+00]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-1.67209e-02, -6.25175e-02, -2.38638e-01,  ..., -4.83919e+00, -4.86320e+00, -5.06508e+00],\n",
            "           [-2.78866e-03, -8.35647e-02, -2.67464e-01,  ..., -4.82925e+00, -4.85119e+00, -5.03841e+00],\n",
            "           [ 5.12837e-04, -6.81280e-02, -2.70180e-01,  ..., -4.82021e+00, -4.86296e+00, -5.03832e+00],\n",
            "           ...,\n",
            "           [-2.61924e-03, -7.69102e-02, -1.75554e-01,  ..., -4.77779e+00, -4.82457e+00, -4.99063e+00],\n",
            "           [-1.12788e-02, -9.08586e-02, -2.26211e-01,  ..., -4.82985e+00, -4.87289e+00, -5.00796e+00],\n",
            "           [ 4.02386e-03, -4.23479e-02, -2.00665e-01,  ..., -4.80332e+00, -4.83485e+00, -5.04619e+00]],\n",
            "\n",
            "          [[-1.17305e-02, -5.83730e-02, -2.40638e-01,  ..., -4.82873e+00, -4.86651e+00, -5.07102e+00],\n",
            "           [-5.66865e-03, -6.62476e-02, -2.63330e-01,  ..., -4.83038e+00, -4.85587e+00, -5.04045e+00],\n",
            "           [-1.12912e-02, -6.28690e-02, -2.68504e-01,  ..., -4.81781e+00, -4.85390e+00, -5.03441e+00],\n",
            "           ...,\n",
            "           [-2.71832e-02, -8.71932e-02, -1.80693e-01,  ..., -4.82844e+00, -4.79510e+00, -5.01280e+00],\n",
            "           [-3.30206e-02, -9.74592e-02, -2.13556e-01,  ..., -4.84513e+00, -4.81751e+00, -4.99558e+00],\n",
            "           [-2.52824e-02, -8.31185e-02, -1.90889e-01,  ..., -4.83540e+00, -4.80779e+00, -5.03319e+00]],\n",
            "\n",
            "          [[-1.96792e-02, -6.84791e-02, -2.32001e-01,  ..., -4.81194e+00, -4.88963e+00, -5.08604e+00],\n",
            "           [ 1.99722e-03, -7.37431e-02, -2.55725e-01,  ..., -4.83314e+00, -4.86939e+00, -5.04955e+00],\n",
            "           [ 1.42428e-03, -7.96088e-02, -2.58352e-01,  ..., -4.82505e+00, -4.86557e+00, -5.04004e+00],\n",
            "           ...,\n",
            "           [-6.01897e-02, -1.54475e-01, -1.83682e-01,  ..., -4.88343e+00, -4.85353e+00, -5.06248e+00],\n",
            "           [-4.44818e-02, -1.51612e-01, -2.25400e-01,  ..., -4.88900e+00, -4.86894e+00, -5.03276e+00],\n",
            "           [-3.58999e-02, -1.13064e-01, -2.24130e-01,  ..., -4.85109e+00, -4.85291e+00, -5.05435e+00]]]]], grad_fn=<CloneBackward0>), tensor([[[[[-1.11392e-01, -1.50655e-01, -7.65150e-02,  ..., -4.79942e+00, -4.95363e+00, -4.87955e+00],\n",
            "           [-8.66471e-02, -6.04605e-02, -8.36458e-02,  ..., -4.88795e+00, -4.97527e+00, -4.88805e+00],\n",
            "           [-8.70814e-02, -5.48914e-02, -8.07981e-02,  ..., -4.87649e+00, -4.97645e+00, -4.87335e+00],\n",
            "           ...,\n",
            "           [-7.63639e-02, -2.12179e-01, -6.81594e-02,  ..., -4.92611e+00, -4.80170e+00, -4.76251e+00],\n",
            "           [-1.03641e-01, -8.30657e-02, -1.35791e-01,  ..., -4.90642e+00, -4.79810e+00, -4.83811e+00],\n",
            "           [-8.39379e-03, -1.65002e-01, -2.27734e-02,  ..., -4.89814e+00, -4.94335e+00, -4.87559e+00]],\n",
            "\n",
            "          [[-1.53911e-01, -1.14040e-01,  1.47796e-02,  ..., -4.78159e+00, -4.93193e+00, -4.85918e+00],\n",
            "           [-1.56654e-01, -4.96139e-02,  6.60342e-02,  ..., -4.85837e+00, -4.94317e+00, -4.87037e+00],\n",
            "           [-1.59941e-01, -6.10173e-02,  5.62523e-02,  ..., -4.84361e+00, -4.94294e+00, -4.85318e+00],\n",
            "           ...,\n",
            "           [-1.35448e-01, -2.12039e-01,  1.47699e-01,  ..., -4.78441e+00, -4.73324e+00, -4.70429e+00],\n",
            "           [-2.56883e-02, -1.78492e-01, -1.06319e-01,  ..., -4.77586e+00, -4.75133e+00, -4.83592e+00],\n",
            "           [-3.51383e-02, -1.22660e-01,  2.54976e-02,  ..., -4.78796e+00, -4.94545e+00, -4.92309e+00]],\n",
            "\n",
            "          [[-1.61176e-01, -1.26049e-01, -2.13752e-03,  ..., -4.77382e+00, -4.94173e+00, -4.86235e+00],\n",
            "           [-1.53975e-01, -5.92662e-02,  5.57259e-02,  ..., -4.84830e+00, -4.96070e+00, -4.88424e+00],\n",
            "           [-1.49626e-01, -7.38895e-02,  5.06189e-02,  ..., -4.83895e+00, -4.95475e+00, -4.87969e+00],\n",
            "           ...,\n",
            "           [-1.03295e-01, -2.60050e-01,  1.19562e-01,  ..., -4.77822e+00, -4.78864e+00, -4.76289e+00],\n",
            "           [ 4.99280e-02, -2.60888e-01, -9.26522e-02,  ..., -4.84214e+00, -4.66111e+00, -4.86771e+00],\n",
            "           [-4.97722e-02, -1.47567e-01,  1.28341e-02,  ..., -4.78475e+00, -4.92729e+00, -4.93298e+00]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-1.65280e-01, -1.36949e-01, -1.69002e-02,  ..., -4.78549e+00, -4.95035e+00, -4.88844e+00],\n",
            "           [-1.78579e-01, -9.67552e-02,  2.88919e-02,  ..., -4.85466e+00, -4.96740e+00, -4.86906e+00],\n",
            "           [-1.55368e-01, -9.83622e-02,  3.03360e-02,  ..., -4.83827e+00, -4.96368e+00, -4.87859e+00],\n",
            "           ...,\n",
            "           [-5.00528e-02, -2.74108e-01, -2.99262e-01,  ..., -4.97427e+00, -4.86257e+00, -4.68170e+00],\n",
            "           [-2.41604e-01, -4.31349e-01,  8.90970e-02,  ..., -4.76571e+00, -4.80797e+00, -4.87320e+00],\n",
            "           [-1.57155e-01, -3.55089e-01, -1.64648e-03,  ..., -4.93523e+00, -4.86010e+00, -4.72241e+00]],\n",
            "\n",
            "          [[-1.69061e-01, -1.53236e-01, -1.99454e-02,  ..., -4.76970e+00, -4.94863e+00, -4.90181e+00],\n",
            "           [-1.72934e-01, -1.00624e-01,  2.07675e-02,  ..., -4.83503e+00, -4.96084e+00, -4.90288e+00],\n",
            "           [-1.71734e-01, -1.09116e-01,  2.68783e-02,  ..., -4.83184e+00, -4.96797e+00, -4.89485e+00],\n",
            "           ...,\n",
            "           [-1.91881e-01, -3.65480e-01, -1.93267e-01,  ..., -4.88011e+00, -4.82555e+00, -4.90333e+00],\n",
            "           [-1.16956e-01, -4.56026e-01,  1.22114e-01,  ..., -4.78749e+00, -4.81456e+00, -4.89843e+00],\n",
            "           [-3.09258e-02, -3.02237e-01, -5.02892e-02,  ..., -4.88987e+00, -4.91833e+00, -4.65188e+00]],\n",
            "\n",
            "          [[-1.43721e-01, -1.22592e-01,  1.22109e-02,  ..., -4.71885e+00, -4.90263e+00, -4.90635e+00],\n",
            "           [-1.22556e-01, -1.10389e-01,  6.71332e-02,  ..., -4.72542e+00, -4.88615e+00, -4.92684e+00],\n",
            "           [-1.13244e-01, -1.12128e-01,  7.78299e-02,  ..., -4.71339e+00, -4.87881e+00, -4.93762e+00],\n",
            "           ...,\n",
            "           [-9.76769e-02, -1.83993e-01,  3.88450e-02,  ..., -4.89429e+00, -4.97541e+00, -4.89019e+00],\n",
            "           [-1.18667e-02, -1.81426e-01,  8.08847e-02,  ..., -4.76274e+00, -4.88043e+00, -4.86752e+00],\n",
            "           [ 5.64471e-02, -2.40283e-01,  1.34743e-01,  ..., -4.79644e+00, -4.93599e+00, -4.83602e+00]]],\n",
            "\n",
            "\n",
            "         [[[ 1.53013e-01,  7.14587e-02, -1.76990e-02,  ..., -4.62018e+00, -4.91512e+00, -4.74061e+00],\n",
            "           [ 1.12030e-01,  8.69820e-02, -4.73254e-02,  ..., -4.63339e+00, -4.93762e+00, -4.71683e+00],\n",
            "           [ 1.12571e-01,  6.64468e-02, -4.37577e-02,  ..., -4.63232e+00, -4.92882e+00, -4.71037e+00],\n",
            "           ...,\n",
            "           [-1.69210e-02, -2.14601e-01, -5.50488e-02,  ..., -4.99849e+00, -4.64596e+00, -4.93248e+00],\n",
            "           [ 4.41005e-02, -2.62603e-02,  5.56586e-03,  ..., -4.83228e+00, -4.78642e+00, -4.87198e+00],\n",
            "           [ 2.21886e-02,  1.08027e-01, -4.13496e-02,  ..., -4.77768e+00, -4.85921e+00, -4.74977e+00]],\n",
            "\n",
            "          [[ 9.72259e-02,  9.54963e-02,  1.85454e-02,  ..., -4.62650e+00, -4.88829e+00, -4.75396e+00],\n",
            "           [ 8.07208e-02,  6.16368e-02, -7.60850e-03,  ..., -4.60813e+00, -4.92760e+00, -4.72670e+00],\n",
            "           [ 8.85339e-02,  5.11529e-02, -1.35462e-02,  ..., -4.59934e+00, -4.95114e+00, -4.71723e+00],\n",
            "           ...,\n",
            "           [-3.69891e-02,  9.69791e-02,  3.86306e-02,  ..., -4.91289e+00, -4.85829e+00, -5.02260e+00],\n",
            "           [-2.95205e-03,  1.58759e-01, -3.47706e-02,  ..., -4.76392e+00, -4.83184e+00, -4.84196e+00],\n",
            "           [ 2.75146e-02,  1.24102e-01, -7.48394e-02,  ..., -4.79895e+00, -4.88795e+00, -4.74490e+00]],\n",
            "\n",
            "          [[ 1.03180e-01,  9.59748e-02,  1.61957e-02,  ..., -4.61952e+00, -4.89347e+00, -4.75377e+00],\n",
            "           [ 8.05898e-02,  6.22027e-02, -2.44608e-02,  ..., -4.58920e+00, -4.92632e+00, -4.73544e+00],\n",
            "           [ 8.65096e-02,  5.99676e-02, -2.68663e-02,  ..., -4.58283e+00, -4.94820e+00, -4.72211e+00],\n",
            "           ...,\n",
            "           [-6.82441e-03,  9.60712e-02,  7.05048e-02,  ..., -4.88689e+00, -4.83398e+00, -5.02028e+00],\n",
            "           [ 3.85940e-02,  2.04038e-01,  4.71476e-02,  ..., -4.72411e+00, -4.86097e+00, -4.81976e+00],\n",
            "           [ 2.82862e-02,  1.35874e-01, -5.88669e-02,  ..., -4.79262e+00, -4.89375e+00, -4.73635e+00]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 9.17072e-02,  9.55954e-02,  1.61707e-02,  ..., -4.64552e+00, -4.89738e+00, -4.80236e+00],\n",
            "           [ 8.04543e-02,  6.28576e-02, -7.20613e-03,  ..., -4.64448e+00, -4.94985e+00, -4.77995e+00],\n",
            "           [ 1.15011e-01,  5.68913e-02,  8.61453e-03,  ..., -4.61063e+00, -4.94668e+00, -4.80400e+00],\n",
            "           ...,\n",
            "           [-1.77234e-01,  6.39537e-02,  4.35643e-02,  ..., -4.94889e+00, -4.62720e+00, -5.01078e+00],\n",
            "           [-2.66654e-01,  1.48948e-01, -6.57627e-02,  ..., -4.70644e+00, -4.80055e+00, -5.00729e+00],\n",
            "           [ 8.79572e-03,  1.88041e-01, -1.50249e-01,  ..., -4.97865e+00, -4.83003e+00, -4.72153e+00]],\n",
            "\n",
            "          [[ 1.06737e-01,  9.99735e-02,  1.54948e-02,  ..., -4.65339e+00, -4.89455e+00, -4.80016e+00],\n",
            "           [ 8.65820e-02,  7.58178e-02, -3.15848e-02,  ..., -4.61553e+00, -4.93679e+00, -4.78204e+00],\n",
            "           [ 9.20610e-02,  6.41951e-02, -3.71942e-02,  ..., -4.62236e+00, -4.94632e+00, -4.77211e+00],\n",
            "           ...,\n",
            "           [-1.02522e-01,  1.39481e-01, -5.66899e-02,  ..., -4.86427e+00, -4.70398e+00, -4.99995e+00],\n",
            "           [-3.39764e-01,  3.22357e-01, -8.27212e-02,  ..., -4.77736e+00, -4.66232e+00, -4.97980e+00],\n",
            "           [-1.36926e-01,  1.84302e-01, -1.49486e-01,  ..., -4.66249e+00, -4.87955e+00, -4.82779e+00]],\n",
            "\n",
            "          [[ 9.59975e-02,  5.98497e-02,  6.20474e-03,  ..., -4.69826e+00, -4.93356e+00, -4.75278e+00],\n",
            "           [ 7.29993e-02,  5.92839e-02, -5.41380e-03,  ..., -4.63590e+00, -4.97766e+00, -4.73957e+00],\n",
            "           [ 7.36870e-02,  6.64797e-02, -1.77310e-02,  ..., -4.64418e+00, -4.98762e+00, -4.72705e+00],\n",
            "           ...,\n",
            "           [-2.50942e-01,  3.30397e-01,  8.01109e-02,  ..., -4.86998e+00, -4.71316e+00, -4.74870e+00],\n",
            "           [-2.79683e-01,  2.93960e-01, -1.69170e-02,  ..., -4.86143e+00, -4.60608e+00, -4.76854e+00],\n",
            "           [-3.42609e-02,  2.44826e-01, -6.62800e-02,  ..., -4.73637e+00, -4.95302e+00, -4.78557e+00]]],\n",
            "\n",
            "\n",
            "         [[[-2.60514e-02, -5.90071e-02, -4.99597e-02,  ..., -4.87271e+00, -4.95606e+00, -5.22103e+00],\n",
            "           [-7.86638e-02, -5.18339e-02, -5.48029e-02,  ..., -4.82495e+00, -4.93590e+00, -5.17588e+00],\n",
            "           [-9.90726e-02, -4.39421e-02, -5.66097e-02,  ..., -4.83734e+00, -4.94082e+00, -5.16465e+00],\n",
            "           ...,\n",
            "           [ 1.53725e-01,  2.95943e-01, -3.28616e-02,  ..., -5.12490e+00, -5.02967e+00, -4.82794e+00],\n",
            "           [ 1.14406e-01,  2.26432e-01,  9.30471e-03,  ..., -4.91611e+00, -4.83578e+00, -5.11001e+00],\n",
            "           [ 6.19924e-02,  7.46078e-02, -1.77287e-01,  ..., -4.95706e+00, -4.97651e+00, -5.10871e+00]],\n",
            "\n",
            "          [[-2.31598e-02, -8.21643e-02, -6.66830e-02,  ..., -4.86287e+00, -4.98357e+00, -5.17223e+00],\n",
            "           [-6.46692e-02, -3.29758e-02, -8.16603e-02,  ..., -4.83323e+00, -4.91172e+00, -5.14251e+00],\n",
            "           [-8.44137e-02, -4.45195e-02, -7.23543e-02,  ..., -4.84308e+00, -4.91265e+00, -5.13744e+00],\n",
            "           ...,\n",
            "           [ 2.69807e-02,  1.64895e-01,  7.32966e-02,  ..., -5.04348e+00, -4.78398e+00, -4.81151e+00],\n",
            "           [ 8.73241e-02,  1.86550e-01,  4.88179e-02,  ..., -5.00410e+00, -4.82157e+00, -5.02758e+00],\n",
            "           [ 1.59569e-01,  1.23017e-01, -2.01606e-01,  ..., -5.04066e+00, -4.97752e+00, -5.13080e+00]],\n",
            "\n",
            "          [[-3.02868e-02, -9.31783e-02, -6.10520e-02,  ..., -4.85586e+00, -4.97936e+00, -5.17798e+00],\n",
            "           [-6.88786e-02, -4.87183e-02, -8.12546e-02,  ..., -4.82950e+00, -4.91080e+00, -5.16423e+00],\n",
            "           [-8.23544e-02, -5.88547e-02, -9.38508e-02,  ..., -4.84070e+00, -4.91592e+00, -5.15634e+00],\n",
            "           ...,\n",
            "           [-4.11787e-02,  2.72802e-01,  8.22782e-02,  ..., -5.07236e+00, -4.88755e+00, -4.77707e+00],\n",
            "           [-5.21532e-03,  1.89343e-01,  6.57336e-02,  ..., -4.99513e+00, -4.81080e+00, -5.00291e+00],\n",
            "           [ 1.39468e-01,  1.32191e-01, -1.83352e-01,  ..., -5.03885e+00, -4.99811e+00, -5.10323e+00]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-4.76288e-02, -7.75542e-02, -4.50685e-02,  ..., -4.84072e+00, -4.97206e+00, -5.17005e+00],\n",
            "           [-5.79286e-02, -2.18616e-02, -5.70934e-02,  ..., -4.80923e+00, -4.90088e+00, -5.16563e+00],\n",
            "           [-6.90085e-02, -3.77051e-02, -6.69856e-02,  ..., -4.79137e+00, -4.92517e+00, -5.13596e+00],\n",
            "           ...,\n",
            "           [-3.24047e-01,  3.00443e-01,  2.06209e-01,  ..., -4.91478e+00, -4.96770e+00, -5.07703e+00],\n",
            "           [-1.98475e-01,  1.34027e-01,  2.65242e-01,  ..., -4.74568e+00, -4.61779e+00, -5.23277e+00],\n",
            "           [-4.37592e-02,  1.42073e-01,  1.04261e-01,  ..., -4.92678e+00, -4.54265e+00, -5.04807e+00]],\n",
            "\n",
            "          [[-3.29826e-02, -7.66337e-02, -4.71016e-02,  ..., -4.84873e+00, -4.97197e+00, -5.15476e+00],\n",
            "           [-5.36560e-02, -4.00304e-02, -7.98431e-02,  ..., -4.81332e+00, -4.90574e+00, -5.15762e+00],\n",
            "           [-6.76656e-02, -4.16370e-02, -7.32187e-02,  ..., -4.82842e+00, -4.90938e+00, -5.14296e+00],\n",
            "           ...,\n",
            "           [-4.28735e-01,  3.04081e-01,  7.04548e-02,  ..., -4.92141e+00, -4.84888e+00, -4.81603e+00],\n",
            "           [ 1.40933e-02,  4.88297e-02,  2.82594e-01,  ..., -4.77518e+00, -4.60784e+00, -5.02736e+00],\n",
            "           [ 1.34788e-01,  2.73240e-03,  7.08815e-02,  ..., -4.82469e+00, -4.62045e+00, -5.00924e+00]],\n",
            "\n",
            "          [[-4.50093e-02, -6.75000e-02,  3.31433e-02,  ..., -4.82791e+00, -5.00744e+00, -5.12783e+00],\n",
            "           [-2.01359e-02, -7.98438e-02,  7.28296e-03,  ..., -4.82742e+00, -4.95490e+00, -5.12841e+00],\n",
            "           [-3.73184e-02, -7.37791e-02,  1.64082e-02,  ..., -4.84117e+00, -4.95914e+00, -5.11571e+00],\n",
            "           ...,\n",
            "           [-1.56312e-01,  1.25070e-01,  7.73999e-02,  ..., -4.88855e+00, -5.00228e+00, -4.85578e+00],\n",
            "           [ 3.03707e-01, -2.09573e-02,  2.59331e-02,  ..., -4.80166e+00, -4.90871e+00, -5.08830e+00],\n",
            "           [ 2.78823e-01,  6.26869e-02, -3.69904e-02,  ..., -4.79755e+00, -4.82328e+00, -5.04004e+00]]]]], grad_fn=<CloneBackward0>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import torch\n",
        "\n",
        "from yolov5.models.yolo import Model\n",
        "\n",
        "import requests\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from io import BytesIO\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "1. torch: PyTorch library for tensor operations and model inference.\n",
        "2. Model from YOLOv5: For initializing the YOLOv5 model.\n",
        "3. requests: To fetch the image from a URL.\n",
        "4. PIL.Image: To handle and manipulate image data (for example, resizing).\n",
        "5. BytesIO: Allows in-memory image manipulation by converting the raw image data from a URL to a usable format.\n",
        "6. numpy: To convert the image into a format suitable for PyTorch tensors."
      ],
      "metadata": {
        "id": "4RvWlggczZPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model = Model('yolov5/models/yolov5s.yaml')\n",
        "\n",
        "\n",
        "This initializes a YOLOv5 model using the yolov5s.yaml configuration file, which defines the small version of YOLOv5. The model will be used for detection."
      ],
      "metadata": {
        "id": "gyNf2BB3zkKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "img_url = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'\n",
        "\n",
        "response = requests.get(img_url, stream=True)\n",
        "\n",
        "response.raise_for_status()\n",
        "\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "1. The requests.get function fetches the image from the URL provided.\n",
        "\n",
        "2. response.raise_for_status() ensures that the request was successful. If there‚Äôs an error (like a 404 or 500 status), it will raise an exception.\n",
        "\n",
        "3. The image is loaded into Python as a PIL.Image object using Image.open and BytesIO to handle the byte stream.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rXqGoNQwzsLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "stride = model.stride.max()\n",
        "\n",
        "width, height = image.size\n",
        "\n",
        "new_width = int(width // stride * stride)\n",
        "\n",
        "new_height = int(height // stride * stride)\n",
        "\n",
        "image = image.resize((new_width, new_height))\n",
        "\n",
        "\n",
        "\n",
        "1. The stride of the model determines the scale at which the model expects the image dimensions to be (usually a multiple of the stride).\n",
        "2. The image is resized so that both the width and height are divisible by the model‚Äôs stride, ensuring proper model input dimensions."
      ],
      "metadata": {
        "id": "xGSIK1N20NOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "image_tensor = torch.from_numpy(np.array(image)).float() / 255.0\n",
        "\n",
        "image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "1. The image is first converted into a NumPy array using np.array(image), then normalized by dividing by 255.0 to scale the pixel values between 0 and 1.\n",
        "\n",
        "2. The permute(2, 0, 1) rearranges the dimensions of the image to be in the format (C, H, W), which is expected by PyTorch models (channels, height, width).\n",
        "\n",
        "3. unsqueeze(0) adds a batch dimension, turning the image into a 4D tensor of shape (1, C, H, W).\n"
      ],
      "metadata": {
        "id": "zed9Zsb40e9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "results = model(image_tensor, augment=False)\n",
        "\n",
        "\n",
        "1. This line runs the YOLOv5 model on the preprocessed image tensor.\n",
        "\n",
        "2. augment=False means no augmentation (such as flipping or scaling) is applied during inference."
      ],
      "metadata": {
        "id": "DzQV0Jx20t44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "print(results)\n",
        "\n",
        "\n",
        "The result is printed into the console."
      ],
      "metadata": {
        "id": "RQoGurO_02oJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "\n",
        "img_url = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'\n",
        "\n",
        "\n",
        "response = requests.get(img_url, stream=True)\n",
        "response.raise_for_status()\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "stride = model.stride\n",
        "\n",
        "\n",
        "width, height = image.size\n",
        "new_width = int(width // stride * stride)\n",
        "new_height = int(height // stride * stride)\n",
        "\n",
        "\n",
        "image = image.resize((new_width, new_height))\n",
        "\n",
        "\n",
        "image_tensor = torch.from_numpy(np.array(image)).float() / 255.0\n",
        "\n",
        "\n",
        "image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "\n",
        "results = model(image_tensor, augment=False)\n",
        "\n",
        "\n",
        "predictions = results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if predictions is not None and len(predictions) > 0:\n",
        "\n",
        "    predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    boxes = predictions[:, :4]  # x1, y1, x2, y2\n",
        "    scores = predictions[:, 4]\n",
        "    categories = predictions[:, 5]\n",
        "\n",
        "\n",
        "    print(\"Bounding Boxes:\", boxes)\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Categories:\", categories)\n",
        "else:\n",
        "    print(\"No predictions found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-v8jPAqPkgy",
        "outputId": "8b99c911-d91d-4460-8b4d-7c8d338d922e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 üöÄ v7.0-381-g15c40626 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bounding Boxes: [[[     3.7897      3.5525      8.7376      9.2005  1.6453e-05     0.17101    0.003249    0.020939   0.0020397   0.0012155  0.00099775   0.0012066   0.0022684   0.0027962    0.020073   0.0013283   0.0021578   0.0026821   0.0057406    0.023332   0.0026077   0.0018693   0.0013557   0.0025085   0.0014635  0.00089966\n",
            "    0.00049605  0.00087233  0.00073435   0.0039125   0.0065071   0.0079966   0.0076682   0.0029883   0.0012382   0.0019318  0.00079908   0.0097088   0.0031081   0.0021366  0.00089273   0.0022841    0.001849   0.0016624    0.037371    0.011498    0.049773   0.0075174    0.020427     0.01506   0.0095858    0.013544\n",
            "     0.0081817   0.0017002    0.015569   0.0029441   0.0079965    0.001939   0.0027551   0.0077377   0.0039581    0.080604   0.0027227     0.01755   0.0014399    0.011663   0.0022037   0.0049376   0.0023665   0.0022184   0.0073053   0.0017301    0.010217   0.0017462   0.0022757  0.00055843   0.0063652   0.0017521\n",
            "      0.019661    0.020281   0.0090109   0.0036919   0.0036532    0.001093   0.0038407]\n",
            "  [     12.312      4.1105      25.389      8.3051  1.4693e-05     0.16159    0.004788    0.037899   0.0026867   0.0017353   0.0013441   0.0016155   0.0031728   0.0043783    0.013607   0.0011692   0.0022487   0.0025984   0.0094842    0.024233   0.0030242   0.0023165   0.0017404   0.0032426   0.0019975   0.0012392\n",
            "     0.0006482   0.0012339   0.0009673   0.0048435    0.009239   0.0076754   0.0064393   0.0035734   0.0015938   0.0027111   0.0010536   0.0090934   0.0034174   0.0026817   0.0010748   0.0033106   0.0026462   0.0020214    0.026802    0.011064    0.052073   0.0079601    0.017224    0.015846    0.016994     0.00841\n",
            "     0.0083547   0.0017637     0.01259   0.0027773   0.0080373   0.0021969   0.0033932   0.0093682   0.0047571    0.088768   0.0034461    0.014507   0.0021713    0.021263   0.0030831   0.0047454   0.0030545   0.0034105   0.0095358   0.0025526    0.014421   0.0021556   0.0032469  0.00080106    0.012205   0.0021601\n",
            "      0.019794     0.02255   0.0067724   0.0044158   0.0039403   0.0016093   0.0038326]\n",
            "  [     17.779      4.1725      32.513        8.42  6.4326e-06     0.19357   0.0053608    0.039699   0.0026979   0.0014721   0.0011594   0.0014323   0.0032541   0.0040342    0.017973   0.0013634   0.0025596   0.0031312   0.0079688    0.025381    0.003151   0.0023922   0.0018844   0.0034321   0.0019161   0.0011985\n",
            "    0.00070834    0.001178  0.00096324   0.0066596   0.0085383    0.011162   0.0088268   0.0042177   0.0017975   0.0028177   0.0010987    0.011982   0.0036608   0.0022149   0.0013305   0.0030743   0.0029502   0.0018442    0.023052   0.0090989    0.047779   0.0063061   0.0099998    0.010963    0.010186   0.0078085\n",
            "     0.0073787   0.0016389    0.012468   0.0027292   0.0085902   0.0022915   0.0028586    0.010529   0.0046432    0.085903   0.0029126      0.0123   0.0018926    0.011916   0.0029375   0.0042266   0.0023295   0.0036061   0.0099241   0.0022473    0.016805   0.0015915     0.00221  0.00075023   0.0075984   0.0019158\n",
            "      0.018756    0.029347   0.0061415   0.0036467   0.0041544   0.0016583   0.0039645]\n",
            "  [     26.742      3.9343      31.125      7.7245  2.8691e-06     0.24132   0.0049579       0.032   0.0024092   0.0012128  0.00099003   0.0012078   0.0024048   0.0028891    0.024672   0.0015094   0.0027301   0.0038215   0.0063638    0.027317   0.0030321   0.0021473   0.0016369     0.00321   0.0017025   0.0011441\n",
            "    0.00066818   0.0010752  0.00091504    0.006829   0.0084414    0.010314    0.011507   0.0041556   0.0017901   0.0027221   0.0010073    0.017096   0.0032991   0.0021879   0.0013116   0.0029638   0.0026219   0.0017294    0.030476   0.0099598    0.047813   0.0073954    0.010881    0.012666   0.0073996   0.0087942\n",
            "     0.0088477   0.0015646    0.018535   0.0031006    0.011598   0.0026751   0.0029059    0.011515   0.0046392    0.074893   0.0026542    0.012449   0.0017452   0.0096979   0.0028576   0.0035662   0.0020515   0.0041353    0.011492   0.0023312    0.019396   0.0014061   0.0019555  0.00068049   0.0072231   0.0017385\n",
            "      0.016672    0.037816   0.0071515    0.003957   0.0042947   0.0016622   0.0046674]]]\n",
            "Scores: [[      35.73      4.0531       29.87      7.3796  2.0851e-06     0.27999   0.0053183    0.028384   0.0023005  0.00093457  0.00077929   0.0011484    0.002032    0.002454    0.024161   0.0015627   0.0022125   0.0037609    0.005849    0.033047    0.003411   0.0026972   0.0018625   0.0043675    0.001888   0.0010923\n",
            "    0.0008041   0.0010625   0.0010453   0.0069515   0.0070515    0.011321    0.012744   0.0047155   0.0016296    0.002595  0.00085123    0.018725   0.0029988   0.0018977   0.0013795   0.0025926   0.0021065   0.0015451    0.031393   0.0095097    0.036313   0.0070178   0.0095611    0.010303   0.0049045     0.01377\n",
            "     0.011822   0.0019427    0.026838   0.0040519    0.015558   0.0034125   0.0029373    0.017535   0.0053126    0.083897   0.0024181    0.011169   0.0015902   0.0065493   0.0021754   0.0028747   0.0014538   0.0037795     0.01193   0.0021123    0.021088   0.0011661   0.0016381  0.00061858   0.0046158   0.0014833\n",
            "      0.01517    0.038495   0.0069921   0.0033175   0.0054285   0.0013431   0.0042652]]\n",
            "Categories: [[     44.966      3.6419       27.34      6.7765  3.0704e-06     0.27217   0.0055354    0.029193   0.0024429   0.0010192  0.00080086   0.0010594   0.0019912   0.0027927    0.025899   0.0015462   0.0021684   0.0035505   0.0059305    0.038108   0.0033219   0.0027199    0.001926    0.004842   0.0020107     0.00111\n",
            "   0.00080678   0.0011797   0.0010857   0.0067356   0.0066833    0.011278    0.013278   0.0044236   0.0016745   0.0030727  0.00091816    0.019419   0.0035064   0.0021351   0.0014277   0.0027824   0.0023033   0.0017229    0.028061   0.0099946    0.037291   0.0078765   0.0096962    0.011146   0.0051278    0.014883\n",
            "     0.011116   0.0019602    0.024395   0.0043333    0.015284   0.0032409   0.0029304    0.017743   0.0051062    0.078553   0.0021893    0.010414   0.0014604    0.005917   0.0021997   0.0024874   0.0013696   0.0039198    0.011984   0.0020131    0.019657   0.0010311   0.0014813  0.00057035   0.0047052   0.0013794\n",
            "     0.015989    0.034112   0.0066355   0.0033893   0.0052342   0.0013228    0.004705]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:865: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. torch: Used for tensor operations and model inference.\n",
        "2. requests: Used to fetch the image from the given URL.\n",
        "3. PIL.Image: Provides methods for opening, manipulating, and saving images.\n",
        "4. BytesIO: Allows you to work with the image in memory (as a byte stream).\n",
        "5. numpy: Converts the image into a NumPy array before transforming it into a tensor.\n"
      ],
      "metadata": {
        "id": "WXpSpoM42zyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "\n",
        "1. This loads the YOLOv5s model from the ultralytics/yolov5 GitHub repository using torch.hub.\n",
        "\n",
        "2. The pretrained=True argument ensures that you load a pre-trained model, which has already been trained on the COCO dataset."
      ],
      "metadata": {
        "id": "ad00WY4_3Byg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "img_url = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'\n",
        "\n",
        "response = requests.get(img_url, stream=True)\n",
        "\n",
        "response.raise_for_status()\n",
        "\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "1. img_url: URL of the image to be processed.\n",
        "2. requests.get(img_url): Fetches the image from the URL as a byte stream.\n",
        "3. response.raise_for_status(): Checks for any request errors (e.g., 404 or 500).\n",
        "4. Image.open(BytesIO(response.content)): Converts the image byte stream into a PIL.Image object."
      ],
      "metadata": {
        "id": "2QSLs0ev4hfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "stride = model.stride\n",
        "\n",
        "width, height = image.size\n",
        "\n",
        "new_width = int(width // stride * stride)\n",
        "\n",
        "new_height = int(height // stride * stride)\n",
        "\n",
        "image = image.resize((new_width, new_height))\n",
        "\n",
        "\n",
        "1. stride: The stride of the model determines the scale at which the model expects the input image dimensions.\n",
        "\n",
        "2. Resizing: The image dimensions are adjusted to be divisible by the model‚Äôs stride. This step ensures that the image size is appropriate for inference and avoids issues during the convolutional operations of the model."
      ],
      "metadata": {
        "id": "nqLZlkCO4w_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "image_tensor = torch.from_numpy(np.array(image)).float() / 255.0\n",
        "\n",
        "image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "\n",
        "1. np.array(image): Converts the PIL image into a NumPy array.\n",
        "\n",
        "2. / 255.0: Normalizes the pixel values from [0, 255] to [0, 1], which is standard for deep learning models.\n",
        "\n",
        "3. permute(2, 0, 1): Changes the image shape from (height, width, channels) to (channels, height, width) as required by PyTorch models.\n",
        "\n",
        "4. unsqueeze(0): Adds a batch dimension, turning the image into a 4D tensor of shape (1, channels, height, width)."
      ],
      "metadata": {
        "id": "SwL9Tv7P5CNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "results = model(image_tensor, augment=False)\n",
        "\n",
        "1. This line runs the YOLOv5 model on the preprocessed image tensor.\n",
        "\n",
        "2. augment=False means no augmentation (such as flipping or scaling) is applied during inference."
      ],
      "metadata": {
        "id": "aCNZhqMv5gmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "predictions = results\n",
        "\n",
        "\n",
        "The results variable contains the raw predictions made by the YOLOv5 model. It includes bounding boxes, class scores, and class labels."
      ],
      "metadata": {
        "id": "uQy-e4pk5qSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if predictions is not None and len(predictions) > 0:\n",
        "    predictions = predictions.detach().cpu().numpy()\n",
        "    boxes = predictions[:, :4]  # x1, y1, x2, y2\n",
        "    scores = predictions[:, 4]\n",
        "    categories = predictions[:, 5]\n",
        "\n",
        "    print(\"Bounding Boxes:\", boxes)\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Categories:\", categories)\n",
        "else:\n",
        "    print(\"No predictions found\")\n",
        "\n",
        "\n",
        "1. Check for Predictions: This ensures that there are predictions to process.\n",
        "\n",
        "2. predictions.detach().cpu().numpy(): Moves the predictions to the CPU and converts the result into a NumPy array for easier processing.\n",
        "\n",
        "3. Extracting Components:\n",
        " -boxes: The first four values represent the bounding box coordinates: x1, y1, x2, y2.\n",
        " -scores: The fifth value represents the confidence score (probability) for each detection.\n",
        " -categories: The sixth value is the class ID of the detected object.\n",
        "4. The results are then printed to the console."
      ],
      "metadata": {
        "id": "qLAYGpet54Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if results is not None and isinstance(results, torch.Tensor) and results.dim() > 0:\n",
        "    print(results)\n",
        "\n",
        "\n",
        "    results_for_render = results\n",
        "\n",
        "\n",
        "    results = results.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    results_for_render.render()\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow(results_for_render.render()[0])\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"No predictions found.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_eWEC0ZS8-X",
        "outputId": "d091602b-2455-47ad-b135-d0c33bb9bc6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No predictions found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if results is not None and isinstance(results, torch.Tensor) and results.dim() > 0:\n",
        "    print(results)\n",
        "\n",
        "\n",
        "1. results is not None: Checks if there are any results from the model.\n",
        "\n",
        "2. isinstance(results, torch.Tensor): Verifies that the results is a tensor (the expected format for PyTorch model outputs).\n",
        "\n",
        "3. results.dim() > 0: Checks that the tensor has dimensions greater than 0, ensuring there is data to process.\n",
        "\n",
        "4. If these conditions are true, the model's results are printed out."
      ],
      "metadata": {
        "id": "vI9eVGgW6QJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "results_for_render = results\n",
        "\n",
        "results = results.detach().cpu().numpy()\n",
        "\n",
        "results_for_render.render()\n",
        "\n",
        "\n",
        "\n",
        "1. results_for_render = results: Keeps a reference to the original result for rendering later.\n",
        "2. results.detach().cpu().numpy(): Detaches the tensor from the computation graph, moves it to the CPU (if it was on a GPU), and converts it to a NumPy array. This allows you to perform further operations on it without affecting the model's computation graph.\n",
        "3. results_for_render.render(): This method is used by YOLOv5‚Äôs results object to draw bounding boxes and labels on the image for visualization. This step modifies the image to include the detection annotations."
      ],
      "metadata": {
        "id": "HhS_C7O0-sJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(results_for_render.render()[0])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "1. plt.imshow(results_for_render.render()[0]): The render() method returns a list of images with bounding boxes drawn. Since there may be multiple images in a batch, render()[0] accesses the first image in the batch.\n",
        "\n",
        "2. plt.show(): Displays the image with the rendered detections using matplotlib"
      ],
      "metadata": {
        "id": "KUUnV627-5NK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "else:\n",
        "    print(\"No predictions found.\")\n",
        "\n",
        "\n",
        "If the conditions for valid results are not met (i.e., no detections), it prints \"No predictions found.\"."
      ],
      "metadata": {
        "id": "NUd2_c_7A_Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if results is not None and isinstance(results, torch.Tensor) and results.dim() > 0:\n",
        "    print(results)\n",
        "\n",
        "\n",
        "    results_for_render = results\n",
        "\n",
        "\n",
        "    results_for_render.save(save_dir='results/')\n",
        "\n",
        "\n",
        "    results = results.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    results_for_render.render()\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow(results_for_render.render()[0])\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"No predictions found.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgvj9MNqTK17",
        "outputId": "0fb42385-8365-41bc-bb70-340ec3f9d9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No predictions found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if results is not None and isinstance(results, torch.Tensor) and results.dim() > 0:\n",
        "    print(results)\n",
        "\n",
        "\n",
        "This part remains the same as in the previous code. It checks whether the results are valid (i.e., the object is a non-empty tensor)."
      ],
      "metadata": {
        "id": "mETCV5VVBUE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "results_for_render = results\n",
        "\n",
        "\n",
        "results_for_render = results: Keeps a reference to the original result object for rendering later without modifying the original data."
      ],
      "metadata": {
        "id": "1N1ZnE0oBXh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "results_for_render.save(save_dir='results/')\n",
        "\n",
        "\n",
        "results_for_render.save(save_dir='results/'): This line saves the rendered results (i.e., the image with the bounding boxes and labels drawn) to a directory named 'results/'. If the directory does not exist, it will be created. The saved images will have the detections drawn on them."
      ],
      "metadata": {
        "id": "upVvYdtWBc6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "results = results.detach().cpu().numpy()\n",
        "results_for_render.render()\n",
        "\n",
        "\n",
        "1. results.detach().cpu().numpy(): Detaches the results from the computation graph, moves them to the CPU if necessary, and converts them into a NumPy array for further operations.\n",
        "\n",
        "2. results_for_render.render(): The render() method is called to draw the bounding boxes, class labels, and scores on the image. It prepares the image for visualization."
      ],
      "metadata": {
        "id": "VwzUzgdrBiln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(results_for_render.render()[0])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "1. plt.imshow(results_for_render.render()[0]): Displays the image with the detected objects. Since render() returns a list of images (in case there are multiple in a batch), [0] selects the first image in the batch.\n",
        "\n",
        "2. plt.show(): Shows the image in the plot.\n",
        "\n"
      ],
      "metadata": {
        "id": "FTvo8PdDBr7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "else:\n",
        "    print(\"No predictions found.\")\n",
        "\n",
        "\n",
        "If the results are empty or invalid, this part ensures the program doesn't crash and outputs \"No predictions found.\"."
      ],
      "metadata": {
        "id": "qkLXqcLVB4dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolov5 train --data data.yaml --img 416 --batch 16 --weights turhancan97/yolov5-detect-trash-classification --epochs 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5MYBlkQTSOL",
        "outputId": "8c91a1e4-6494-4d25-e9e3-a8f3991f571a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-08 15:01:25.101231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-08 15:01:25.357291: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-08 15:01:25.434229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=turhancan97/yolov5-detect-trash-classification, cfg=, data=data.yaml, hyp=../../usr/local/lib/python3.10/dist-packages/yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, bbox_interval=-1, artifact_alias=latest, neptune_token=None, neptune_project=None, neptune_resume_id=None, s3_upload_dir=None, upload_dataset=False, hf_model_id=None, hf_token=None, hf_private=False, hf_dataset_id=None, roboflow_token=None, roboflow_upload=False, img=416, batch=16\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /usr/local/lib/python3.10/dist-packages/requirements.txt not found, check failed.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolov5\", line 8, in <module>\n",
            "    sys.exit(app())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/yolov5/cli.py\", line 18, in app\n",
            "    fire.Fire(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 135, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/yolov5/train.py\", line 730, in run_cli\n",
            "    main(opt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/yolov5/train.py\", line 590, in main\n",
            "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/yolov5/utils/general.py\", line 459, in check_file\n",
            "    assert len(files), f'File not found: {file}'  # assert file was found\n",
            "AssertionError: File not found: data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Process: The training process will start, and YOLOv5 will attempt to fine-tune the pre-trained model (turhancan97/yolov5-detect-trash-classification) on the dataset defined in data.yaml for 10 epochs.\n",
        "\n",
        "Output: The process will output logs showing the training progress, loss values, and accuracy. The model weights will be saved after training, and the results will be stored in the specified output directory."
      ],
      "metadata": {
        "id": "lpAxzngEB-9B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://ultralytics.com/hub\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/im/integrations-loop.png\"/></a></p>\n",
        "Close the active learning loop by sampling images from your inference conditions with the `roboflow` pip package\n",
        "<br><br>\n",
        "\n",
        "Train a YOLOv5s model on the [COCO128](https://www.kaggle.com/datasets/ultralytics/coco128) dataset with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`.\n",
        "\n",
        "- **Pretrained [Models](https://github.com/ultralytics/yolov5/tree/master/models)** are downloaded\n",
        "automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)\n",
        "- **[Datasets](https://github.com/ultralytics/yolov5/tree/master/data)** available for autodownload include: [COCO](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml), [COCO128](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml), [VOC](https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml), [Argoverse](https://github.com/ultralytics/yolov5/blob/master/data/Argoverse.yaml), [VisDrone](https://github.com/ultralytics/yolov5/blob/master/data/VisDrone.yaml), [GlobalWheat](https://github.com/ultralytics/yolov5/blob/master/data/GlobalWheat2020.yaml), [xView](https://github.com/ultralytics/yolov5/blob/master/data/xView.yaml), [Objects365](https://github.com/ultralytics/yolov5/blob/master/data/Objects365.yaml), [SKU-110K](https://github.com/ultralytics/yolov5/blob/master/data/SKU-110K.yaml).\n",
        "- **Training Results** are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n",
        "<br>\n",
        "\n",
        "A **Mosaic Dataloader** is used for training which combines 4 images into 1 mosaic.\n",
        "\n",
        "## Label a dataset on Roboflow (optional)\n",
        "\n",
        "[Roboflow](https://roboflow.com/?ref=ultralytics) enables you to easily **organize, label, and prepare** a high quality dataset with your own custom data. Roboflow also makes it easy to establish an active learning pipeline, collaborate with your team on dataset improvement, and integrate directly into your model building workflow with the `roboflow` pip package."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv5 üöÄ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'ClearML':\n",
        "  %pip install -q clearml\n",
        "  import clearml; clearml.browser_login()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir runs/train"
      ],
      "metadata": {
        "id": "i3oKtE4g-aNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbeeea2b-04fc-4185-aa64-258690495b5a"
      },
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-09 14:11:38.063605: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-09 14:11:39.026661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v7.0-136-g71244ae Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "Dataset not found ‚ö†Ô∏è, missing paths ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128.zip to coco128.zip...\n",
            "100% 6.66M/6.66M [00:00<00:00, 75.6MB/s]\n",
            "Dataset download success ‚úÖ (0.6s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<00:00, 1709.36it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 264.35it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:01<00:00, 107.05it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/2      3.91G    0.04618    0.07209    0.01703        232        640: 100% 8/8 [00:09<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.01it/s]\n",
            "                   all        128        929      0.667      0.602       0.68       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/2      4.76G    0.04622    0.06891    0.01817        201        640: 100% 8/8 [00:02<00:00,  3.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.16it/s]\n",
            "                   all        128        929      0.709      0.645      0.722      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/2      4.76G     0.0436     0.0647    0.01698        227        640: 100% 8/8 [00:01<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.95it/s]\n",
            "                   all        128        929      0.761      0.647      0.735       0.49\n",
            "\n",
            "3 epochs completed in 0.006 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.8MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.8MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:06<00:00,  1.56s/it]\n",
            "                   all        128        929      0.759      0.646      0.734       0.49\n",
            "                person        128        254      0.857      0.706      0.805      0.525\n",
            "               bicycle        128          6      0.773      0.577      0.725      0.414\n",
            "                   car        128         46      0.664      0.435      0.551       0.24\n",
            "            motorcycle        128          5      0.587        0.8      0.837      0.635\n",
            "              airplane        128          6          1      0.989      0.995      0.715\n",
            "                   bus        128          7      0.635      0.714      0.753      0.651\n",
            "                 train        128          3      0.686      0.333       0.72      0.504\n",
            "                 truck        128         12      0.604      0.333      0.472      0.259\n",
            "                  boat        128          6      0.938      0.333      0.449      0.177\n",
            "         traffic light        128         14      0.778      0.255      0.401      0.217\n",
            "             stop sign        128          2      0.826          1      0.995      0.895\n",
            "                 bench        128          9      0.711      0.556      0.661      0.313\n",
            "                  bird        128         16      0.962          1      0.995      0.642\n",
            "                   cat        128          4      0.868          1      0.995      0.754\n",
            "                   dog        128          9          1      0.652      0.899      0.651\n",
            "                 horse        128          2      0.853          1      0.995      0.622\n",
            "              elephant        128         17      0.909      0.882      0.934      0.698\n",
            "                  bear        128          1      0.696          1      0.995      0.995\n",
            "                 zebra        128          4      0.855          1      0.995      0.905\n",
            "               giraffe        128          9      0.788      0.828      0.912      0.701\n",
            "              backpack        128          6      0.835        0.5      0.738      0.311\n",
            "              umbrella        128         18      0.785      0.814      0.859       0.48\n",
            "               handbag        128         19      0.759      0.263      0.366      0.205\n",
            "                   tie        128          7      0.983      0.714       0.77      0.492\n",
            "              suitcase        128          4      0.656          1      0.945      0.631\n",
            "               frisbee        128          5      0.721        0.8      0.759      0.724\n",
            "                  skis        128          1      0.737          1      0.995        0.3\n",
            "             snowboard        128          7      0.829      0.696       0.83      0.537\n",
            "           sports ball        128          6      0.637      0.667      0.602      0.311\n",
            "                  kite        128         10      0.636        0.6      0.599      0.226\n",
            "          baseball bat        128          4      0.501       0.25      0.468      0.205\n",
            "        baseball glove        128          7      0.483      0.429      0.465      0.292\n",
            "            skateboard        128          5      0.932        0.6      0.687      0.493\n",
            "         tennis racket        128          7       0.77      0.429      0.547      0.332\n",
            "                bottle        128         18      0.577      0.379      0.554      0.276\n",
            "            wine glass        128         16      0.704      0.875       0.89       0.51\n",
            "                   cup        128         36      0.841      0.667      0.837      0.533\n",
            "                  fork        128          6      0.992      0.333       0.45      0.315\n",
            "                 knife        128         16      0.768      0.688      0.695      0.403\n",
            "                 spoon        128         22      0.838       0.47      0.639      0.384\n",
            "                  bowl        128         28      0.764       0.58      0.716      0.513\n",
            "                banana        128          1      0.902          1      0.995      0.301\n",
            "              sandwich        128          2          1          0      0.359      0.326\n",
            "                orange        128          4      0.722       0.75      0.912      0.581\n",
            "              broccoli        128         11      0.547      0.364      0.432      0.317\n",
            "                carrot        128         24      0.619      0.625      0.724      0.495\n",
            "               hot dog        128          2      0.409          1      0.828      0.762\n",
            "                 pizza        128          5      0.833      0.995      0.962      0.727\n",
            "                 donut        128         14      0.631          1       0.96      0.839\n",
            "                  cake        128          4       0.87          1      0.995       0.83\n",
            "                 chair        128         35      0.583        0.6      0.608      0.317\n",
            "                 couch        128          6      0.907      0.667      0.815      0.544\n",
            "          potted plant        128         14      0.739      0.786      0.823       0.48\n",
            "                   bed        128          3      0.985      0.333       0.83      0.441\n",
            "          dining table        128         13      0.821      0.357      0.578      0.342\n",
            "                toilet        128          2          1      0.988      0.995      0.846\n",
            "                    tv        128          2       0.57          1      0.995      0.796\n",
            "                laptop        128          3          1          0      0.593      0.312\n",
            "                 mouse        128          2          1          0      0.089     0.0445\n",
            "                remote        128          8          1      0.624      0.634      0.538\n",
            "            cell phone        128          8      0.622      0.417      0.421      0.187\n",
            "             microwave        128          3      0.711          1      0.995      0.766\n",
            "                  oven        128          5      0.329        0.4       0.43      0.282\n",
            "                  sink        128          6      0.437      0.333      0.338      0.265\n",
            "          refrigerator        128          5      0.567        0.8      0.799      0.536\n",
            "                  book        128         29      0.597      0.257      0.349      0.154\n",
            "                 clock        128          9      0.765      0.889      0.932      0.736\n",
            "                  vase        128          2       0.33          1      0.995      0.895\n",
            "              scissors        128          1          1          0      0.497     0.0498\n",
            "            teddy bear        128         21      0.856      0.569      0.841      0.547\n",
            "            toothbrush        128          5        0.8          1      0.928      0.574\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15glLzbQx5u0"
      },
      "source": [
        "# 4. Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comet Logging and Visualization üåü NEW\n",
        "\n",
        "[Comet](https://www.comet.com/site/lp/yolov5-with-comet/?utm_source=yolov5&utm_medium=partner&utm_campaign=partner_yolov5_2022&utm_content=yolov5_colab) is now fully integrated with YOLOv5. Track and visualize model metrics in real time, save your hyperparameters, datasets, and model checkpoints, and visualize your model predictions with [Comet Custom Panels](https://www.comet.com/docs/v2/guides/comet-dashboard/code-panels/about-panels/?utm_source=yolov5&utm_medium=partner&utm_campaign=partner_yolov5_2022&utm_content=yolov5_colab)! Comet makes sure you never lose track of your work and makes it easy to share results and collaborate across teams of all sizes!\n",
        "\n",
        "Getting started is easy:\n",
        "```shell\n",
        "pip install comet_ml  # 1. install\n",
        "export COMET_API_KEY=<Your API Key>  # 2. paste API key\n",
        "python train.py --img 640 --epochs 3 --data coco128.yaml --weights yolov5s.pt  # 3. train\n",
        "```\n",
        "To learn more about all of the supported Comet features for this integration, check out the [Comet Tutorial](https://docs.ultralytics.com/yolov5/tutorials/comet_logging_integration). If you'd like to learn more about Comet, head over to our [documentation](https://www.comet.com/docs/v2/?utm_source=yolov5&utm_medium=partner&utm_campaign=partner_yolov5_2022&utm_content=yolov5_colab). Get started by trying out the Comet Colab Notebook:\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1RG0WOQyxlDlo5Km8GogJpIEJlg_5lyYO?usp=sharing)\n",
        "\n",
        "<a href=\"https://bit.ly/yolov5-readme-comet2\">\n",
        "<img alt=\"Comet Dashboard\" src=\"https://user-images.githubusercontent.com/26833433/202851203-164e94e1-2238-46dd-91f8-de020e9d6b41.png\" width=\"1280\"/></a>"
      ],
      "metadata": {
        "id": "nWOsI5wJR1o3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ClearML Logging and Automation üåü NEW\n",
        "\n",
        "[ClearML](https://cutt.ly/yolov5-notebook-clearml) is completely integrated into YOLOv5 to track your experimentation, manage dataset versions and even remotely execute training runs. To enable ClearML (check cells above):\n",
        "\n",
        "- `pip install clearml`\n",
        "- run `clearml-init` to connect to a ClearML server (**deploy your own [open-source server](https://github.com/allegroai/clearml-server)**, or use our [free hosted server](https://cutt.ly/yolov5-notebook-clearml))\n",
        "\n",
        "You'll get all the great expected features from an experiment manager: live updates, model upload, experiment comparison etc. but ClearML also tracks uncommitted changes and installed packages for example. Thanks to that ClearML Tasks (which is what we call experiments) are also reproducible on different machines! With only 1 extra line, we can schedule a YOLOv5 training task on a queue to be executed by any number of ClearML Agents (workers).\n",
        "\n",
        "You can use ClearML Data to version your dataset and then pass it to YOLOv5 simply using its unique ID. This will help you keep track of your data without adding extra hassle. Explore the [ClearML Tutorial](https://docs.ultralytics.com/yolov5/tutorials/clearml_logging_integration) for details!\n",
        "\n",
        "<a href=\"https://cutt.ly/yolov5-notebook-clearml\">\n",
        "<img alt=\"ClearML Experiment Management UI\" src=\"https://github.com/thepycoder/clearml_screenshots/raw/main/scalars.jpg\" width=\"1280\"/></a>"
      ],
      "metadata": {
        "id": "Lay2WsTjNJzP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WPvRbS5Swl6"
      },
      "source": [
        "## Local Logging\n",
        "\n",
        "Training results are automatically logged with [Tensorboard](https://www.tensorflow.org/tensorboard) and [CSV](https://github.com/ultralytics/yolov5/pull/4148) loggers to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc.\n",
        "\n",
        "This directory contains train and val statistics, mosaics, labels, predictions and augmentated mosaics, as well as metrics and charts including precision-recall (PR) curves and confusion matrices.\n",
        "\n",
        "<img alt=\"Local logging results\" src=\"https://user-images.githubusercontent.com/26833433/183222430-e1abd1b7-782c-4cde-b04d-ad52926bf818.jpg\" width=\"1280\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zelyeqbyt3GD"
      },
      "source": [
        "# Environments\n",
        "\n",
        "YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):\n",
        "\n",
        "- **Notebooks** with free GPU: <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a> <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a> <a href=\"https://www.kaggle.com/models/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/google_cloud_quickstart_tutorial/)\n",
        "- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/aws_quickstart_tutorial/)\n",
        "- **Docker Image**. See [Docker Quickstart Guide](https://docs.ultralytics.com/yolov5/environments/docker_image_quickstart_tutorial/) <a href=\"https://hub.docker.com/r/ultralytics/yolov5\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker\" alt=\"Docker Pulls\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qu7Iesl0p54"
      },
      "source": [
        "# Status\n",
        "\n",
        "![YOLOv5 CI](https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg)\n",
        "\n",
        "If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training ([train.py](https://github.com/ultralytics/yolov5/blob/master/train.py)), testing ([val.py](https://github.com/ultralytics/yolov5/blob/master/val.py)), inference ([detect.py](https://github.com/ultralytics/yolov5/blob/master/detect.py)) and export ([export.py](https://github.com/ultralytics/yolov5/blob/master/export.py)) on macOS, Windows, and Ubuntu every 24 hours and on every commit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMusP4OAxFu6"
      },
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True, trust_repo=True)  # or yolov5n - yolov5x6 or custom\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}